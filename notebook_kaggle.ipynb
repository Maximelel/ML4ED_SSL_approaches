{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-21T21:00:38.632813Z","iopub.status.busy":"2023-12-21T21:00:38.631647Z","iopub.status.idle":"2023-12-21T21:01:21.138985Z","shell.execute_reply":"2023-12-21T21:01:21.137700Z","shell.execute_reply.started":"2023-12-21T21:00:38.632770Z"},"trusted":true},"outputs":[],"source":["# turn internet on on kaggle before running this cell\n","!pip install transformers[torch]\n","#!pip install accelerate -U  # restart runtime if it still doesn't work\n","!pip install datasets\n","!pip install evaluate"]},{"cell_type":"markdown","metadata":{},"source":["# Notebook \n","\n","**NB:** \n","- Notebook used for the experiments during the project and run on kaggle for computational reason (GPU available)\n","- The code for this project has been run on a cluster with 1 GPU: see python files of the directory run_to_cluster which have all the functions in this notebook structured in a clean way."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T21:06:44.921497Z","iopub.status.busy":"2023-12-21T21:06:44.920544Z","iopub.status.idle":"2023-12-21T21:07:15.301667Z","shell.execute_reply":"2023-12-21T21:07:15.300649Z","shell.execute_reply.started":"2023-12-21T21:06:44.921450Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import regex as re\n","import torch\n","from tqdm import tqdm\n","from pandas.api.types import CategoricalDtype\n","\n","import evaluate\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import KFold\n","from datasets import load_metric\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","import warnings\n","warnings.filterwarnings('ignore') # parameters : default or ignore\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Load datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T21:07:26.071942Z","iopub.status.busy":"2023-12-21T21:07:26.070602Z","iopub.status.idle":"2023-12-21T21:07:26.280556Z","shell.execute_reply":"2023-12-21T21:07:26.279452Z","shell.execute_reply.started":"2023-12-21T21:07:26.071903Z"},"trusted":true},"outputs":[],"source":["# import sentences\n","sentences_en_tr = pd.read_csv('../input/cered-dataset/data/sentences/en/train/sentences.tsv',sep='\\t')\n","sentences_en_val = pd.read_csv('../input/cered-dataset/data/sentences/en/val/sentences.tsv',sep='\\t')\n","sentences_en_te = pd.read_csv('../input/cered-dataset/data/sentences/en/test/sentences.tsv',sep='\\t')\n","print(f'In English\\nLenght training set : {len(sentences_en_tr)}')\n","print(f'Lenght validation set : {len(sentences_en_val)}')\n","print(f'Lenght testing set : {len(sentences_en_te)}')\n","\n","sentences_en_te.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T21:07:27.717682Z","iopub.status.busy":"2023-12-21T21:07:27.717282Z","iopub.status.idle":"2023-12-21T21:07:27.754433Z","shell.execute_reply":"2023-12-21T21:07:27.753494Z","shell.execute_reply.started":"2023-12-21T21:07:27.717651Z"},"trusted":true},"outputs":[],"source":["# preprocess\n","\n","# Change Difficuties to Difficulty in 'y' column of test dataset\n","sentences_en_te['y'] = np.where(sentences_en_te['y'] == 'Difficulties', 'Difficulty', sentences_en_te['y'])\n","\n","# Merge the DataFrames\n","merged_df = pd.concat([sentences_en_tr, sentences_en_val, sentences_en_te], ignore_index=True)\n","\n","# Remove the 'Reflection' label\n","merged_df = merged_df[merged_df['y'] != 'Reflection']\n","\n","# Shuffle the merged DataFrame\n","merged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","train_dataset, original_test_dataset = train_test_split(merged_df, test_size=0.15, random_state=42)\n","\n","# Check lengths of sets\n","print(\"Train set length:\", len(train_dataset))\n","print(\"Test set length:\", len(original_test_dataset))\n","\n","train_dataset.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T21:07:29.099484Z","iopub.status.busy":"2023-12-21T21:07:29.099112Z","iopub.status.idle":"2023-12-21T21:07:31.197724Z","shell.execute_reply":"2023-12-21T21:07:31.196691Z","shell.execute_reply.started":"2023-12-21T21:07:29.099453Z"},"trusted":true},"outputs":[],"source":["M_catType = CategoricalDtype(categories = ['Difficulty', 'Experience', 'Other', 'Feeling', 'Belief', 'Perspective', 'Intention', 'Learning'], ordered = True)\n","fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n","\n","# Plot distribution of labels for each DataFrame\n","for i, df in enumerate([sentences_en_tr, sentences_en_val, sentences_en_te]):\n","    df['y'] = df['y'].astype(M_catType)\n","    sns.histplot(df['y'], ax=axs[i])\n","    axs[i].set_title(f'Distribution of Labels - DataFrame {i+1}')\n","    axs[i].tick_params(axis='x',labelrotation = 45)\n","plt.suptitle(\"Before preprocessing\")\n","plt.tight_layout()\n","plt.show()\n","\n","fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n","\n","# Plot distribution of labels for each DataFrame\n","for i, df in enumerate([train_dataset, original_test_dataset]):\n","    df['y'] = df['y'].astype(M_catType)\n","    sns.histplot(df['y'], ax=axs[i])\n","    axs[i].set_title(f'Distribution of Labels - DataFrame {i+1}')\n","    axs[i].tick_params(axis='x',labelrotation = 45)\n","\n","plt.suptitle(\"After preprocessing\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Handle class imbalance of test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import RandomOverSampler\n","\n","\n","under_sampler = RandomUnderSampler(sampling_strategy = 'not minority')\n","balanced_test_dataset_down, _ = under_sampler.fit_resample(original_test_dataset, original_test_dataset['y'])\n","\n","over_sampler = RandomOverSampler(sampling_strategy='all', random_state=42)\n","balanced_test_dataset_up, _ = over_sampler.fit_resample(original_test_dataset, original_test_dataset['y'])\n","\n","small_balanced_test_dataset_up = balanced_test_dataset_up.sample(frac = 0.5)\n","# under sample again to have perfect distribution\n","under_sampler = RandomUnderSampler(sampling_strategy = 'not minority')\n","small_balanced_test_dataset_up, _ = under_sampler.fit_resample(small_balanced_test_dataset_up, small_balanced_test_dataset_up['y'])\n","\n","fig, axs = plt.subplots(1, 4, figsize=(15, 4), sharey = True) \n","sns.histplot(original_test_dataset['y'], ax=axs[0])\n","sns.histplot(balanced_test_dataset_down['y'], ax=axs[1])\n","sns.histplot(balanced_test_dataset_up['y'], ax=axs[2])\n","sns.histplot(small_balanced_test_dataset_up['y'], ax=axs[3])\n","axs[0].set_title('Original Test Dataset')\n","axs[1].set_title('Balanced Test Dataset with downsampling')\n","axs[2].set_title('Balanced Test Dataset with upsampling')\n","axs[3].set_title('Small Balanced Test Dataset with upsampling')\n","axs[0].tick_params(axis='x',labelrotation = 45)\n","axs[1].tick_params(axis='x',labelrotation = 45)\n","axs[2].tick_params(axis='x',labelrotation = 45)\n","axs[3].tick_params(axis='x',labelrotation = 45)\n","plt.tight_layout()\n","plt.show()\n","\n","# define a dictionary for the different test datasets\n","list_test_datasets = {\"original_test_dataset\": original_test_dataset, \"balanced_test_dataset_down\": balanced_test_dataset_down, \"balanced_test_dataset_up\": balanced_test_dataset_up, \"small_balanced_test_dataset_up\": small_balanced_test_dataset_up}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for dataset_name, dataset in list_test_datasets.items():\n","    print(f\"Length of {dataset_name}: {len(dataset)}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Define functions\n","\n","- preprocess_data\n","- prepare_model\n","- train\n","- evaluate\n","- train_test\n","- prepare_test_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T21:07:35.337685Z","iopub.status.busy":"2023-12-21T21:07:35.337262Z","iopub.status.idle":"2023-12-21T21:07:35.407957Z","shell.execute_reply":"2023-12-21T21:07:35.406833Z","shell.execute_reply.started":"2023-12-21T21:07:35.337651Z"},"trusted":true},"outputs":[],"source":["def preprocess_data(df_sentences_train, df_sentences_test):\n","    df_train = pd.DataFrame()\n","    df_test = pd.DataFrame()\n","\n","    # Preprocess data and labels\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","\n","    max_length_train = max(df_sentences_train['sentence'].apply(lambda sentence: len(sentence.split())))\n","    max_length_test = max(df_sentences_test['sentence'].apply(lambda sentence: len(sentence.split())))\n","\n","    df_train['text'] = df_sentences_train['sentence'].apply(\n","        lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_train))\n","    df_test['text'] = df_sentences_test['sentence'].apply(\n","        lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_test))\n","    \n","    label_encoder_train = LabelEncoder()\n","    label_encoder_test = LabelEncoder()\n","    df_test['label'] = label_encoder_train.fit_transform(df_sentences_test['y'])\n","    df_train['label'] = label_encoder_test.fit_transform(df_sentences_train['y']) # in output for evaluation\n","    \n","    # Split the data into training and validation sets\n","    train_data, val_data = train_test_split(df_train, test_size=0.2, random_state=42)\n","    test_data = df_test\n","    print(f\"Train data : {len(train_data)}\")\n","    print(f\"Val data : {len(val_data)}\")\n","    print(f\"Test data : {len(test_data)}\")\n","    \n","    # Create a custom dataset\n","    class CustomDataset(Dataset):\n","        def __init__(self, text, label):\n","            self.text = text\n","            self.label = label\n","        def __len__(self):\n","            return len(self.text)\n","        def __getitem__(self, idx):\n","            return {\n","              'text': torch.tensor(self.text[idx], dtype=torch.long),\n","              'label': torch.tensor(self.label[idx], dtype=torch.long)\n","          }\n","    train_dataset_pp = CustomDataset(train_data['text'].values, train_data['label'].values)\n","    val_dataset_pp = CustomDataset(val_data['text'].values, val_data['label'].values)\n","    test_dataset_pp = CustomDataset(test_data['text'].values, test_data['label'].values)\n","\n","    return train_dataset_pp, val_dataset_pp, test_dataset_pp, label_encoder_test\n","\n","def prepare_model(model, train_dataset_pp, val_dataset_pp, test_dataset_pp, freeze_weights, batch_size, epochs, learning_rate):\n","\n","    if freeze_weights:\n","        # Freeze all layers except the last two\n","        for param in model.parameters():\n","            param.requires_grad = False\n","        for param in model.classifier.parameters():\n","            param.requires_grad = True\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset_pp, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset_pp, batch_size=batch_size)\n","    test_loader = DataLoader(test_dataset_pp, batch_size=batch_size)\n","\n","    # Set up optimizer and scheduler\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)\n","\n","    return train_loader, val_loader, test_loader, optimizer, scheduler\n","\n","def train(model, train_loader, epochs, optimizer, scheduler, device, plot_visualization):\n","    accuracy_metric = load_metric(\"accuracy\")\n","    train_losses = []\n","    avg_acc_per_epoch = []\n","\n","    for epoch in range(epochs):\n","        #print(f\"epoch {epoch} running...\")\n","        model.train()\n","        train_loss = []\n","        acc = []\n","        all_preds = []\n","        all_labels = []\n","\n","        for batch in tqdm(train_loader, position = 0, desc= f\"epoch {epoch} running...\"):\n","            optimizer.zero_grad()\n","            inputs = batch['text'].to(device)\n","            labels = batch['label'].to(device)\n","            outputs = model(inputs, labels=labels)\n","            loss = outputs.loss\n","            train_loss.append(loss.item())\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","            ### to plot accuracy during training ###\n","            predictions = torch.argmax(outputs.logits, axis=1)\n","            all_preds.extend(predictions.cpu().numpy().tolist())\n","            all_labels.extend(labels.tolist())\n","            ########################################\n","        avg_epoch_loss = sum(train_loss) / len(train_loss)\n","        train_losses.append(avg_epoch_loss)\n","        avg_acc_per_epoch.append(accuracy_metric.compute(predictions=all_preds, references=all_labels)[\"accuracy\"])\n","    \n","    if plot_visualization == True:\n","        fig, axs = plt.subplots(1,2, figsize = (12,5))\n","        axs[0].plot(range(epochs), train_losses, label='Training Loss')\n","        axs[0].set_xlabel('Epoch')\n","        axs[0].set_ylabel('Loss')\n","        axs[0].set_title('Training Loss over Epochs')\n","        axs[0].set_xticks(np.arange(epochs))\n","        axs[0].legend()\n","\n","        axs[1].plot(range(epochs), avg_acc_per_epoch, label='Training Accuracy')\n","        axs[1].set_xlabel('Epoch')\n","        axs[1].set_ylabel('Accuracy')\n","        axs[1].set_title('Training Accuracy over Epochs')\n","        axs[1].set_xticks(np.arange(epochs))\n","        axs[1].legend()\n","        plt.show()\n","    \n","    return train_losses, avg_acc_per_epoch\n","\n","def evaluate(model, test_loader, label_encoder, device, plot_results, accuracy_metric):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    pred_confidence = []\n","    train_confidence_scores = []\n","    correct_confidence = []\n","    incorrect_confidence = []\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            inputs = batch['text'].to(device)\n","            labels = batch['label'].to(device)\n","            outputs = model(inputs)\n","            predictions = torch.argmax(outputs.logits, axis=1)\n","            all_preds.extend(predictions.cpu().numpy().tolist())\n","            all_labels.extend(labels.tolist())\n","            ### compute confidence score\n","            probabilities = torch.softmax(outputs.logits, dim=1)\n","            pred_confidence.extend(probabilities.max(dim=1).values.cpu().detach().numpy())  # Confidence scores\n","            ###\n","\n","    # compute accuracy\n","    accuracy = accuracy_metric.compute(predictions=all_preds, references=all_labels)[\"accuracy\"]\n","    print(f\"Accuracy: {np.round(accuracy,3)}\")\n","    # Decode label encodings\n","    predicted_labels = label_encoder.inverse_transform(all_preds)\n","    true_labels = label_encoder.inverse_transform(all_labels)\n","\n","    # Get unique labels from true and predicted labels and their union for the confusion matrix\n","    unique_true_labels = set(predicted_labels)\n","    unique_predicted_labels = set(true_labels)\n","    unique_labels_union = unique_true_labels.union(unique_predicted_labels)\n","    \n","    print(unique_labels_union)\n","    # Sort the labels alphabetically to ensure consistent order\n","    class_labels = sorted(unique_labels_union)\n","    \n","    \n","    if plot_results:\n","        # Generate classification report\n","        report = classification_report(true_labels, predicted_labels, zero_division = 1, target_names=class_labels)\n","        print(report)\n","\n","        # Create confusion matrix\n","        cm = confusion_matrix(true_labels, predicted_labels, labels=class_labels)\n","\n","        fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n","        # Subplot 1: Confusion Matrix\n","        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels, ax=axs[0])\n","        axs[0].set_xlabel(\"Predicted\")\n","        axs[0].set_ylabel(\"True\")\n","        axs[0].set_title(\"Confusion Matrix\")\n","\n","        # Subplot 2: Confidence Scores Histogram\n","        #axs[1].hist(pred_confidence, bins=50)\n","        #axs[1].set_xlabel('Confidence score')\n","        #axs[1].set_ylabel('Number of predictions')\n","        #axs[1].set_title('Confidence score of predictions')\n","        \n","        # Subplot 3: Confidence Scores Histogram for Correct and Incorrect Predictions\n","        correct_confidence = [pred_confidence[i] for i in range(len(predicted_labels)) if predicted_labels[i] == true_labels[i]]\n","        incorrect_confidence = [pred_confidence[i] for i in range(len(predicted_labels)) if predicted_labels[i] != true_labels[i]]\n","        axs[1].hist(correct_confidence, bins=50, color='green', alpha=0.7, label='Correct Predictions')\n","        axs[1].hist(incorrect_confidence, bins=50, color='red', alpha=0.7, label='Incorrect Predictions')\n","        axs[1].set_xlabel('Confidence score')\n","        axs[1].set_ylabel('Number of predictions')\n","        axs[1].set_title('Confidence score of predictions')\n","        axs[1].legend()\n","\n","        plt.tight_layout()\n","        plt.show()\n","        \n","    ###### print for cluster######\n","    #predicted_labels = [', '.join(predicted_labels)]\n","    #true_labels = [', '.join(true_labels)]\n","    print(f\"\\npredicted_labels = {predicted_labels}\")\n","    print(f\"\\ntrue_labels = {true_labels}\")\n","    print(f\"\\npred_confidence = {pred_confidence}\")\n","    print(f\"\\nclass_labels = {class_labels}\")\n","    \n","    #print(f\"\\n Missing labels : {set(['Belief', 'Difficulty', 'Experience', 'Feeling', 'Other', 'Learning', 'Perspective', 'Intention']) - unique_labels_union}\\n\")\n","    \n","\n","def train_test(model, train_loader, val_loader, epochs, optimizer, scheduler, device):\n","    accuracy_metric = load_metric(\"accuracy\")\n","    train_losses = []\n","    val_losses = []\n","    avg_train_acc_per_epoch = []\n","    avg_val_acc_per_epoch = []\n","    train_confidence_scores_avg_per_epoch = []  # Store confidence scores for train set\n","    val_confidence_scores = []    # Store confidence scores for validation set\n","    avg_balanced_train_acc_per_epoch = [] \n","    avg_balanced_val_acc_per_epoch = [] \n","\n","    for epoch in range(epochs):\n","    #for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n","        #print(f\"epoch {epoch} running...\")\n","        model.train()\n","        train_loss = []\n","        all_preds_train = []\n","        all_labels_train = []\n","        all_train_confidence = []\n","\n","        #for batch in train_loader:\n","        for batch in tqdm(train_loader, position = 0, desc= f\"epoch {epoch} running...\"):\n","            optimizer.zero_grad()\n","            inputs = batch['text'].to(device)\n","            labels = batch['label'].to(device)\n","            outputs = model(inputs, labels=labels)\n","            loss = outputs.loss\n","            train_loss.append(loss.item())\n","            predictions_train = torch.argmax(outputs.logits, axis=1)\n","            all_preds_train.extend(predictions_train.cpu().numpy().tolist())\n","            all_labels_train.extend(labels.tolist())\n","            ### compute confidence score\n","            probabilities = torch.softmax(outputs.logits, dim=1)\n","            all_train_confidence.extend(probabilities.max(dim=1).values.cpu().detach().numpy())  # Confidence scores\n","            ###\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","        avg_epoch_loss_train = sum(train_loss) / len(train_loss)\n","        train_losses.append(avg_epoch_loss_train)\n","        avg_train_acc_per_epoch.append(accuracy_metric.compute(predictions=all_preds_train, references=all_labels_train)[\"accuracy\"])\n","        avg_balanced_train_acc_per_epoch.append(balanced_accuracy_score(all_labels_train, all_preds_train))\n","        train_confidence_scores_avg_per_epoch.append(np.mean(all_train_confidence))  # Store confidence scores\n","        \n","        # Validation loop\n","        model.eval()\n","        val_loss = []\n","        all_preds_val = []\n","        all_labels_val = []\n","        val_confidence = []\n","\n","        with torch.no_grad():\n","            for batch in val_loader: \n","            #for batch in val_loader:\n","                inputs = batch['text'].to(device)\n","                labels = batch['label'].to(device)\n","                outputs = model(inputs, labels=labels)\n","                loss_val = outputs.loss\n","                val_loss.append(loss_val.item())\n","                predictions_val = torch.argmax(outputs.logits, axis=1)\n","                all_preds_val.extend(predictions_val.cpu().numpy().tolist())\n","                all_labels_val.extend(labels.tolist())\n","                probabilities = torch.softmax(outputs.logits, dim=1)\n","                val_confidence.extend(probabilities.max(dim=1).values.cpu().detach().numpy())  # Confidence scores\n","\n","        avg_epoch_loss_val = sum(val_loss) / len(val_loss)\n","        val_losses.append(avg_epoch_loss_val)\n","        avg_val_acc_per_epoch.append(accuracy_metric.compute(predictions=all_preds_val, references=all_labels_val)[\"accuracy\"])\n","        avg_balanced_val_acc_per_epoch.append(balanced_accuracy_score(all_labels_val, all_preds_val))\n","        val_confidence_scores.append(np.mean(val_confidence))  # Store confidence scores\n","\n","    return train_losses, val_losses, avg_train_acc_per_epoch, avg_val_acc_per_epoch, train_confidence_scores_avg_per_epoch, val_confidence_scores, all_train_confidence, avg_balanced_train_acc_per_epoch, avg_balanced_val_acc_per_epoch\n","\n","def prepare_test_dataset(df_sentences_test, batch_size):\n","\n","    df_test = pd.DataFrame()\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","    max_length_test = max(df_sentences_test['sentence'].apply(lambda sentence: len(sentence.split())))\n","    df_test['text'] = df_sentences_test['sentence'].apply(\n","            lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_test))\n","\n","    label_encoder_test = LabelEncoder()\n","    df_test['label'] = label_encoder_test.fit_transform(df_sentences_test['y'])\n","\n","    # Create a custom dataset\n","    class CustomDataset(Dataset):\n","        def __init__(self, text, label):\n","            self.text = text\n","            self.label = label\n","        def __len__(self):\n","            return len(self.text)\n","        def __getitem__(self, idx):\n","            return {\n","                'text': torch.tensor(self.text[idx], dtype=torch.long),\n","                'label': torch.tensor(self.label[idx], dtype=torch.long)\n","            }\n","\n","    test_dataset = CustomDataset(df_test['text'].values, df_test['label'].values)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","    return test_loader, label_encoder_test\n","\n","def preprocess_data_train_test(df_sentences_train, df_sentences_test):\n","    df_train = pd.DataFrame()\n","    df_test = pd.DataFrame()\n","\n","    # Preprocess data and labels\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","\n","    max_length_train = max(df_sentences_train['sentence'].apply(lambda sentence: len(sentence.split())))\n","    max_length_test = max(df_sentences_test['sentence'].apply(lambda sentence: len(sentence.split())))\n","\n","    df_train['text'] = df_sentences_train['sentence'].apply(\n","        lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_train))\n","    df_test['text'] = df_sentences_test['sentence'].apply(\n","        lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_test))\n","    \n","    label_encoder_train = LabelEncoder()\n","    label_encoder_test = LabelEncoder()\n","    df_test['label'] = label_encoder_train.fit_transform(df_sentences_test['y'])\n","    df_train['label'] = label_encoder_test.fit_transform(df_sentences_train['y']) # in output for evaluation\n","    \n","    # Split the data into training and validation sets\n","    train_data = df_train\n","    test_data = df_test\n","    print(f\"Train data : {len(train_data)}\")\n","    print(f\"Test data : {len(test_data)}\")\n","    \n","    # Create a custom dataset\n","    class CustomDataset(Dataset):\n","        def __init__(self, text, label):\n","            self.text = text\n","            self.label = label\n","        def __len__(self):\n","            return len(self.text)\n","        def __getitem__(self, idx):\n","            return {\n","              'text': torch.tensor(self.text[idx], dtype=torch.long),\n","              'label': torch.tensor(self.label[idx], dtype=torch.long)\n","          }\n","    train_dataset_pp = CustomDataset(train_data['text'].values, train_data['label'].values)\n","    test_dataset_pp = CustomDataset(test_data['text'].values, test_data['label'].values)\n","\n","    return train_dataset_pp, test_dataset_pp, label_encoder_test\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","# Multiclass CLF"]},{"cell_type":"markdown","metadata":{},"source":["#### After HP search with CV"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# after HP search\n","#test_dataset = list_test_datasets['original_test_dataset']\n","test_dataset = original_test_dataset\n","# preprocess data\n","train_dataset_pp, test_dataset_pp, label_encoder_test = preprocess_data_train_test(train_dataset, test_dataset)\n","\n","# Initialize the pre-trained BERT model\n","model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8).to(device)\n","\n","# Define training parameters\n","batch_size, epochs, learning_rate = 8, 3, 2e-5\n","\n","###################################\n","##### prepare model ###############\n","###################################\n","# Create data loaders\n","train_loader = DataLoader(train_dataset_pp, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset_pp, batch_size=batch_size)\n","\n","# Set up optimizer and scheduler\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)\n","\n","# train model with 3 epochs and bs 8\n","train_losses, test_losses, avg_train_acc_per_epoch, avg_test_acc_per_epoch, train_confidence_scores, test_confidence_scores, all_train_confidence, avg_balanced_train_acc_per_epoch, avg_balanced_val_acc_per_epoch  = train_test(\n","                                                                                                                                model,\n","                                                                                                                                train_loader,\n","                                                                                                                                test_loader,\n","                                                                                                                                epochs=epochs,\n","                                                                                                                                optimizer=optimizer,\n","                                                                                                                                scheduler=scheduler,\n","                                                                                                                                device=device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T20:44:57.308493Z","iopub.status.busy":"2023-12-20T20:44:57.307755Z","iopub.status.idle":"2023-12-20T20:44:57.746433Z","shell.execute_reply":"2023-12-20T20:44:57.745539Z","shell.execute_reply.started":"2023-12-20T20:44:57.308456Z"},"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(1,2, figsize = (12,5))\n","axs[0].plot(range(epochs), train_losses, label='Training Loss')\n","axs[0].plot(range(epochs), test_losses, label='Test Loss')\n","axs[0].set_xlabel('Epoch')\n","axs[0].set_ylabel('Loss')\n","axs[0].set_title('Train and Test Loss over Epochs')\n","axs[0].set_xticks(np.arange(epochs))\n","axs[0].legend()\n","\n","axs[1].plot(range(epochs), avg_train_acc_per_epoch, label='Training Accuracy')\n","axs[1].plot(range(epochs), avg_test_acc_per_epoch, label='Test Accuracy')\n","axs[1].set_xlabel('Epoch')\n","axs[1].set_ylabel('Accuracy')\n","axs[1].set_title('Train and Test Accuracy over Epochs')\n","axs[1].set_xticks(np.arange(epochs))\n","axs[1].legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T21:01:19.864707Z","iopub.status.busy":"2023-12-20T21:01:19.864369Z","iopub.status.idle":"2023-12-20T21:06:19.721788Z","shell.execute_reply":"2023-12-20T21:06:19.720783Z","shell.execute_reply.started":"2023-12-20T21:01:19.864681Z"},"trusted":true},"outputs":[],"source":["# train only\n","\n","#test_dataset = list_test_datasets['original_test_dataset']\n","test_dataset = original_test_dataset\n","# preprocess data\n","train_dataset_pp, test_dataset_pp, label_encoder_test = preprocess_data_train_test(train_dataset, test_dataset)\n","\n","# Initialize the pre-trained BERT model\n","model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8).to(device)\n","\n","# Define training parameters\n","batch_size, epochs, learning_rate = 8, 3, 2e-5\n","\n","###################################\n","##### prepare model ###############\n","###################################\n","# Create data loaders\n","train_loader = DataLoader(train_dataset_pp, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset_pp, batch_size=batch_size)\n","\n","# Set up optimizer and scheduler\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)\n","    \n","train_losses, avg_acc_per_epoch = train(model, train_loader, epochs, optimizer, scheduler, device, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["evaluate(model = model,\n","         test_loader = test_loader,\n","         label_encoder = label_encoder_test,\n","         device = device,\n","         plot_results = True,\n","         accuracy_metric = load_metric(\"accuracy\"))"]},{"cell_type":"markdown","metadata":{},"source":["#### Old code"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#test_dataset = list_test_datasets['original_test_dataset']\n","test_dataset = original_test_dataset\n","# preprocess data\n","train_dataset_pp, val_dataset_pp, test_dataset_pp, label_encoder_test = preprocess_data(train_dataset.iloc[:1000], test_dataset)\n","\n","# Initialize the pre-trained BERT model\n","model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8).to(device)\n","\n","# Define training parameters\n","batch_size, epochs, learning_rate = 8, 3, 2e-5\n","freeze_weights = False\n","\n","train_loader, val_loader, test_loader, optimizer, scheduler = prepare_model(model, train_dataset_pp, val_dataset_pp, test_dataset_pp, freeze_weights, batch_size, epochs, learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","\n","train_losses, val_losses, avg_train_acc_per_epoch, avg_val_acc_per_epoch, train_confidence_scores, val_confidence_scores  = train_test(\n","                                                                                                                                model,\n","                                                                                                                                train_loader,\n","                                                                                                                                val_loader,\n","                                                                                                                                epochs=epochs,\n","                                                                                                                                optimizer=optimizer,\n","                                                                                                                                scheduler=scheduler,\n","                                                                                                                                device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(1,2, figsize = (12,5))\n","axs[0].plot(range(epochs), train_losses, label='Training Loss')\n","axs[0].plot(range(epochs), val_losses, label='Validation Loss')\n","axs[0].set_xlabel('Epoch')\n","axs[0].set_ylabel('Loss')\n","axs[0].set_title('Train and Val Loss over Epochs')\n","axs[0].set_xticks(np.arange(epochs))\n","axs[0].legend()\n","\n","axs[1].plot(range(epochs), avg_train_acc_per_epoch, label='Training Accuracy')\n","axs[1].plot(range(epochs), avg_val_acc_per_epoch, label='Validation Accuracy')\n","axs[1].set_xlabel('Epoch')\n","axs[1].set_ylabel('Accuracy')\n","axs[1].set_title('Train and Val Accuracy over Epochs')\n","axs[1].set_xticks(np.arange(epochs))\n","axs[1].legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# evaluate model on test dataset\n","#test_loader, label_encoder_test = prepare_test_dataset(test_dataset, batch_size)\n","\n","evaluate(model = model,\n","         test_loader = test_loader,\n","         label_encoder = label_encoder_test,\n","         device = device,\n","         plot_results = True,\n","         accuracy_metric = load_metric(\"accuracy\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for name, test_data in list_test_datasets.items():\n","    print(f\"Test dataset: {name}\")\n","    test_loader, label_encoder_test = prepare_test_dataset(test_data, batch_size)\n","\n","    evaluate(model = model,\n","             test_loader = test_loader,\n","             label_encoder = label_encoder_test,\n","             device = device,\n","             plot_results = True,\n","             accuracy_metric = load_metric(\"accuracy\"))"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","# Multiclass CLF with CV\n","\n","Functions:\n","- preprocess_data_for_CV\n","- cross_validate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T21:15:16.579682Z","iopub.status.busy":"2023-12-21T21:15:16.578718Z","iopub.status.idle":"2023-12-21T21:15:16.602303Z","shell.execute_reply":"2023-12-21T21:15:16.601194Z","shell.execute_reply.started":"2023-12-21T21:15:16.579588Z"},"trusted":true},"outputs":[],"source":["def preprocess_data_for_CV(df_sentences_train, df_sentences_test, train_index, val_index):\n","    \n","    df_train = pd.DataFrame()\n","    df_test = pd.DataFrame()\n","    \n","    # Preprocess data and labels\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","\n","    max_length_train = max(df_sentences_train['sentence'].apply(lambda sentence: len(sentence.split())))\n","    max_length_test = max(df_sentences_test['sentence'].apply(lambda sentence: len(sentence.split())))\n","\n","    df_train['text'] = df_sentences_train['sentence'].apply(\n","        lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_train))\n","    df_test['text'] = df_sentences_test['sentence'].apply(\n","        lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_test))\n","    \n","    label_encoder_train = LabelEncoder()\n","    label_encoder_test = LabelEncoder()\n","    df_train['label'] = label_encoder_train.fit_transform(df_sentences_train['y']) \n","    df_test['label'] = label_encoder_test.fit_transform(df_sentences_test['y']) # in output for evaluation\n","    \n","    # Split the data into training and validation sets with CV splits\n","    train_data = df_train.iloc[train_index]\n","    val_data = df_train.iloc[val_index]\n","    \n","    test_data = df_test\n","    print(f\"Train data : {len(train_data)}\")\n","    print(f\"Val data : {len(val_data)}\")\n","    print(f\"Test data : {len(test_data)}\")\n","\n","    \n","    # Create a custom dataset\n","    class CustomDataset(Dataset):\n","        def __init__(self, text, label):\n","            self.text = text\n","            self.label = label\n","        def __len__(self):\n","            return len(self.text)\n","        def __getitem__(self, idx):\n","            return {\n","              'text': torch.tensor(self.text[idx], dtype=torch.long),\n","              'label': torch.tensor(self.label[idx], dtype=torch.long)\n","            }\n","    train_dataset = CustomDataset(train_data['text'].values, train_data['label'].values)\n","    val_dataset = CustomDataset(val_data['text'].values, val_data['label'].values)\n","    test_dataset = CustomDataset(test_data['text'].values, test_data['label'].values)\n","\n","    return train_dataset, val_dataset, test_dataset, label_encoder_test\n","\n","def cross_validate(df_sentences_train, df_sentences_test, freeze_weights, batch_size, epochs, learning_rate, n_splits, train_loss_list, train_acc_list, train_balanced_acc_list, val_loss_list, val_acc_list, val_balanced_acc_list, device):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","    best_val_acc = 0.0\n","    best_model = None\n","\n","    for fold, (train_index, val_index) in enumerate(kf.split(df_sentences_train)):\n","        print(f\"Fold {fold + 1}:\")\n","\n","        train_dataset, val_dataset, test_dataset, label_encoder_test = preprocess_data_for_CV(df_sentences_train, df_sentences_test, train_index, val_index)\n","\n","        # Initialize the pre-trained BERT model\n","        model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8).to(device)\n","        train_loader, val_loader, test_loader, optimizer, scheduler = prepare_model(model, train_dataset, val_dataset, test_dataset, freeze_weights, batch_size, epochs, learning_rate)\n","        \n","        train_loss_fold, val_loss_fold, train_acc_fold, val_acc_fold, _, _, _,  train_balanced_acc_fold, val_balanced_acc_fold = train_test(model, train_loader, val_loader, epochs, optimizer, scheduler, device)\n","        \n","        train_loss_list.extend(train_loss_fold)\n","        train_acc_list.extend(train_acc_fold)\n","        val_loss_list.extend(val_loss_fold)\n","        val_acc_list.extend(val_acc_fold) \n","        train_balanced_acc_list.extend(train_balanced_acc_fold)\n","        val_balanced_acc_list.extend(val_balanced_acc_fold)\n","\n","        # Evaluate validation accuracy\n","        val_accuracy = val_acc_fold[-1]  # Assuming val_acc_fold contains accuracy values for each epoch\n","\n","        # Update best model if current fold's validation accuracy is higher\n","        if val_accuracy > best_val_acc:\n","            best_val_acc = val_accuracy\n","            best_model = model.state_dict()  # Store the state dict of the best model\n","        \n","    return train_loss_list, val_loss_list, train_acc_list, train_balanced_acc_list, val_acc_list, val_balanced_acc_list, label_encoder_test, test_loader, best_model"]},{"cell_type":"markdown","metadata":{},"source":["### Train CV"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","\n","# Set hyperparameters\n","batch_size = 8\n","epochs = 3\n","learning_rate = 2e-5\n","n_splits = 3\n","\n","train_loss_list = []\n","train_acc_list = []\n","train_balanced_acc_list = []\n","val_loss_list = []\n","val_acc_list = []\n","val_balanced_acc_list = []\n","\n","train_loss_list, val_loss_list, train_acc_list, train_balanced_acc_list, val_acc_list, val_balanced_acc_list, label_encoder_test, test_loader, best_model  = cross_validate(df_sentences_train=train_dataset.iloc[:1000],\n","                                                                                    df_sentences_test= list_test_datasets['original_test_dataset'],\n","                                                                                    freeze_weights=False, \n","                                                                                    batch_size=batch_size, \n","                                                                                    epochs=epochs, \n","                                                                                    learning_rate=learning_rate,\n","                                                                                    n_splits=n_splits,\n","                                                                                    train_loss_list = train_loss_list,\n","                                                                                    train_acc_list = train_acc_list,\n","                                                                                    train_balanced_acc_list = train_balanced_acc_list,\n","                                                                                    val_loss_list = val_loss_list,\n","                                                                                    val_acc_list = val_acc_list,\n","                                                                                    val_balanced_acc_list = val_balanced_acc_list,\n","                                                                                    device = device)"]},{"cell_type":"markdown","metadata":{},"source":["Print results (loss and accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(f\"bs = {batch_size}\")\n","print(f\"n_splits = {n_splits}\")\n","print(f\"epochs = {epochs}\")\n","print(f\"\\ntrain_loss_list = {train_loss_list}\")\n","print(f\"\\nval_loss_list = {val_loss_list}\")\n","print(f\"\\ntrain_acc_list = {train_acc_list}\")\n","print(f\"\\nval_acc_list = {val_acc_list}\")\n","print(f\"\\ntrain_balanced_acc_list = {train_balanced_acc_list}\")\n","print(f\"\\nval_balanced_acc_list = {val_balanced_acc_list}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_loss_array = np.array(train_loss_list).reshape(n_splits,epochs)\n","mean_train_loss = np.mean(train_loss_array, axis=0)\n","ci_train_loss = np.percentile(train_loss_array, [2.5, 97.5], axis=0)\n","\n","val_loss_array = np.array(val_loss_list).reshape(n_splits,epochs)\n","mean_val_loss = np.mean(val_loss_array, axis=0)\n","ci_val_loss = np.percentile(val_loss_array, [2.5, 97.5], axis=0)\n","\n","# Create a DataFrame for Seaborn\n","df_train_loss = pd.DataFrame({\n","    'Epochs': np.arange(epochs),\n","    'Mean_Train_Loss': mean_train_loss,\n","    'Lower_CI': ci_train_loss[0],\n","    'Upper_CI': ci_train_loss[1]})\n","\n","df_val_loss = pd.DataFrame({\n","    'Epochs': np.arange(epochs),\n","    'Mean_Val_Loss': mean_val_loss,\n","    'Lower_CI': ci_val_loss[0],\n","    'Upper_CI': ci_val_loss[1]})\n","\n","# Code for Accuracy Plot (Second Subplot)\n","train_acc_array = np.array(train_acc_list).reshape(n_splits, epochs)\n","val_acc_array = np.array(val_acc_list).reshape(n_splits, epochs)\n","ci_train_acc = np.percentile(train_acc_array, [2.5, 97.5], axis=0)\n","\n","mean_train_acc = np.mean(train_acc_array, axis=0)\n","mean_val_acc = np.mean(val_acc_array, axis=0)\n","ci_val_acc = np.percentile(val_acc_array, [2.5, 97.5], axis=0)\n","\n","df_train_acc = pd.DataFrame({\n","    'Epochs': np.arange(epochs), \n","    'Mean_Train_Accuracy': mean_train_acc,\n","    'Lower_CI': ci_train_acc[0],\n","    'Upper_CI': ci_train_acc[1]})\n","\n","df_val_acc = pd.DataFrame({\n","    'Epochs': np.arange(epochs),\n","    'Mean_Val_Accuracy': mean_val_acc,\n","    'Lower_CI': ci_val_acc[0],\n","    'Upper_CI': ci_val_acc[1]})\n","\n","# Code for Balanced Accuracy Plot (Second Subplot)\n","train_balanced_acc_array = np.array(train_balanced_acc_list).reshape(n_splits, epochs)\n","val_balanced_acc_array = np.array(val_balanced_acc_list).reshape(n_splits, epochs)\n","ci_train_balanced_acc = np.percentile(train_balanced_acc_array, [2.5, 97.5], axis=0)\n","\n","mean_train_balanced_acc = np.mean(train_balanced_acc_array, axis=0)\n","mean_val_balanced_acc = np.mean(val_balanced_acc_array, axis=0)\n","ci_val_balanced_acc = np.percentile(val_balanced_acc_array, [2.5, 97.5], axis=0)\n","\n","df_train_balanced_acc = pd.DataFrame({\n","    'Epochs': np.arange(epochs), \n","    'Mean_Train_Balanced_Accuracy': mean_train_balanced_acc,\n","    'Lower_CI': ci_train_acc[0],\n","    'Upper_CI': ci_train_acc[1]})\n","\n","df_val_balanced_acc = pd.DataFrame({\n","    'Epochs': np.arange(epochs),\n","    'Mean_Val_Balanced_Accuracy': mean_val_balanced_acc,\n","    'Lower_CI': ci_val_acc[0],\n","    'Upper_CI': ci_val_acc[1]})\n","\n","#df_train_loss.head()\n","#df_val_loss.head()\n","\n","fig, axs = plt.subplots(1,3, figsize=(12,5))\n","# Plot the mean accuracy line\n","sns.pointplot(data=df_train_loss, x='Epochs', y='Mean_Train_Loss', color='blue', ax = axs[0])\n","sns.pointplot(data=df_val_loss, x='Epochs', y='Mean_Val_Loss', color='orange', ax = axs[0])\n","\n","sns.pointplot(data=df_train_acc, x='Epochs', y='Mean_Train_Accuracy', color='blue', ax = axs[1])\n","sns.pointplot(data=df_val_acc, x='Epochs', y='Mean_Val_Accuracy', color='orange', ax = axs[1])\n","\n","sns.pointplot(data=df_train_balanced_acc, x='Epochs', y='Mean_Train_Balanced_Accuracy', color='blue', ax = axs[2])\n","sns.pointplot(data=df_val_balanced_acc, x='Epochs', y='Mean_Val_Balanced_Accuracy', color='orange', ax = axs[2])\n","\n","# Fill between the confidence interval\n","axs[0].fill_between(df_train_loss['Epochs'], df_train_loss['Lower_CI'], df_train_loss['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","axs[0].fill_between(df_val_loss['Epochs'], df_val_loss['Lower_CI'], df_val_loss['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","axs[0].legend()\n","axs[0].set_xlabel('Epochs')\n","axs[0].set_ylabel('Loss')\n","axs[0].set_title('CV Loss with 95% CI')\n","\n","axs[1].fill_between(df_train_acc['Epochs'], df_train_acc['Lower_CI'], df_train_acc['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","axs[1].fill_between(df_val_acc['Epochs'], df_val_acc['Lower_CI'], df_val_acc['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","\n","axs[1].set_xlabel('Epochs')\n","axs[1].set_ylabel('Accuracy')\n","axs[1].set_title('CV Accuracy with 95% CI')\n","\n","axs[2].fill_between(df_train_balanced_acc['Epochs'], df_train_balanced_acc['Lower_CI'], df_train_balanced_acc['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","axs[2].fill_between(df_val_balanced_acc['Epochs'], df_val_balanced_acc['Lower_CI'], df_val_balanced_acc['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","\n","axs[2].set_xlabel('Epochs')\n","axs[2].set_ylabel('Balanced Accuracy')\n","axs[2].set_title('CV Balanced Accuracy with 95% CI')\n","\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Evaluation of the best model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Initialize the model\n","model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=8).to(device)\n","\n","# Load the state dictionary of the best model\n","model.load_state_dict(best_model)\n","\n","# Evaluate the best model\n","evaluate(model=model,\n","             test_loader=test_loader,\n","             label_encoder=label_encoder_test,\n","             device=device,\n","             plot_results = True,\n","             accuracy_metric = load_metric(\"accuracy\"))"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","# Multiple binary CLF with CV"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T21:15:29.410945Z","iopub.status.busy":"2023-12-21T21:15:29.410545Z","iopub.status.idle":"2023-12-21T21:15:29.421783Z","shell.execute_reply":"2023-12-21T21:15:29.420466Z","shell.execute_reply.started":"2023-12-21T21:15:29.410910Z"},"trusted":true},"outputs":[],"source":["def cross_validate_bin(df_sentences_train, df_sentences_test, freeze_weights, batch_size, epochs, learning_rate, n_splits, train_loss_list, train_acc_list, train_balanced_acc_list,val_loss_list, val_acc_list, val_balanced_acc_list, device):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","    best_val_acc = 0.0\n","    best_model = None\n","\n","    for fold, (train_index, val_index) in enumerate(kf.split(df_sentences_train)):\n","        print(f\"Fold {fold + 1}:\")\n","\n","        train_dataset, val_dataset, test_dataset, label_encoder_test = preprocess_data_for_CV(df_sentences_train, df_sentences_test, train_index, val_index)\n","\n","        # Initialize the pre-trained BERT model\n","        model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","        train_loader, val_loader, test_loader, optimizer, scheduler = prepare_model(model, train_dataset, val_dataset, test_dataset, freeze_weights, batch_size, epochs, learning_rate)\n","        \n","        train_loss_fold, val_loss_fold, train_acc_fold, val_acc_fold, _, _, _, train_balanced_acc_fold, val_balanced_acc_fold = train_test(model, train_loader, val_loader, epochs, optimizer, scheduler, device)\n","        \n","        train_loss_list.extend(train_loss_fold)\n","        train_acc_list.extend(train_acc_fold)\n","        val_loss_list.extend(val_loss_fold)\n","        val_acc_list.extend(val_acc_fold) \n","        train_balanced_acc_list.extend(train_balanced_acc_fold)\n","        val_balanced_acc_list.extend(val_balanced_acc_fold)\n","\n","        # Evaluate validation accuracy\n","        val_accuracy = val_acc_fold[-1]  # Assuming val_acc_fold contains accuracy values for each epoch\n","\n","        # Update best model if current fold's validation accuracy is higher\n","        if val_accuracy > best_val_acc:\n","            best_val_acc = val_accuracy\n","            best_model = model.state_dict()  # Store the state dict of the best model\n","        \n","    return train_loss_list, val_loss_list, train_acc_list, train_balanced_acc_list,val_acc_list, val_balanced_acc_list, label_encoder_test, test_loader, best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T21:56:38.596962Z","iopub.status.busy":"2023-12-21T21:56:38.596208Z","iopub.status.idle":"2023-12-21T21:56:38.605113Z","shell.execute_reply":"2023-12-21T21:56:38.604065Z","shell.execute_reply.started":"2023-12-21T21:56:38.596923Z"},"trusted":true},"outputs":[],"source":["# Select the reflective categories and show their distribution\n","reflective_cat_in_order = list(train_dataset[\"y\"].value_counts().sort_values(ascending=False).index)\n","reflective_cat_in_order_wo_other = [item for item in reflective_cat_in_order if item != 'Other']\n","print(f\"List of reflective categories in order : {reflective_cat_in_order}\")\n","print(f\"List of reflective categories in order without 'Other': {reflective_cat_in_order_wo_other}\")\n","\n","topN_classes = reflective_cat_in_order_wo_other[6:]\n","reflective_categories = topN_classes\n","print(f\"\\ntopN reflective categories: {reflective_categories}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:30:56.911840Z","iopub.status.busy":"2023-12-21T22:30:56.911408Z","iopub.status.idle":"2023-12-21T22:35:23.887395Z","shell.execute_reply":"2023-12-21T22:35:23.886354Z","shell.execute_reply.started":"2023-12-21T22:30:56.911808Z"},"trusted":true},"outputs":[],"source":["%%time\n","# Set hyperparameters\n","batch_size = 8\n","epochs = 5\n","learning_rate = 2e-5\n","n_splits = 2\n","\n","dfs_train_loss = {}\n","dfs_train_acc = {}\n","dfs_train_balanced_acc = {}\n","dfs_val_loss = {}\n","dfs_val_acc = {}\n","dfs_val_balanced_acc = {}\n","best_model = {}\n","\n","print(f\"\\n\\nLaunching {n_splits}-fold CV per class with : {reflective_categories}\")\n","\n","for i, cat in enumerate(reflective_categories):\n","    print(f\"\\n\\nCV for {cat}\")\n","    train_loss_list = []\n","    train_acc_list = []\n","    train_balanced_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","    val_balanced_acc_list = []\n","    \n","    df_sentences_bin = train_dataset.iloc[:2000].copy()\n","    df_sentences_bin['y'] = np.where(df_sentences_bin['y'] == cat, cat, 'Other')\n","    \n","    train_loss_list, val_loss_list, train_acc_list, train_balanced_acc_list, val_acc_list, val_balanced_acc_list, label_encoder_test, _, best_model[cat] = cross_validate_bin(df_sentences_train=df_sentences_bin,\n","                                                                                                df_sentences_test = original_test_dataset.iloc[:300],\n","                                                                                                freeze_weights=False, \n","                                                                                                batch_size=batch_size, \n","                                                                                                epochs=epochs, \n","                                                                                                learning_rate=learning_rate,\n","                                                                                                n_splits=n_splits,\n","                                                                                                train_loss_list = train_loss_list,\n","                                                                                                train_acc_list = train_acc_list,\n","                                                                                                train_balanced_acc_list = train_balanced_acc_list,\n","                                                                                                val_loss_list = val_loss_list,\n","                                                                                                val_acc_list = val_acc_list,\n","                                                                                                val_balanced_acc_list = val_balanced_acc_list,\n","                                                                                                device = device)\n","\n","    # loss on training set\n","    train_loss_array = np.array(train_loss_list).reshape(n_splits,epochs)\n","    mean_train_loss = np.mean(train_loss_array, axis=0)\n","    ci_train_loss = np.percentile(train_loss_array, [2.5, 97.5], axis=0)\n","\n","    # loss on validation set\n","    val_loss_array = np.array(val_loss_list).reshape(n_splits,epochs)\n","    mean_val_loss = np.mean(val_loss_array, axis=0)\n","    ci_val_loss = np.percentile(val_loss_array, [2.5, 97.5], axis=0)\n","    \n","    # accuracy on training set\n","    train_acc_array = np.array(train_acc_list).reshape(n_splits,epochs)\n","    mean_train_acc = np.mean(train_acc_array, axis=0)\n","    ci_train_acc = np.percentile(train_acc_array, [2.5, 97.5], axis=0)\n","        \n","    # accuracy on validation set\n","    val_acc_array = np.array(val_acc_list).reshape(n_splits,epochs)\n","    mean_val_acc = np.mean(val_acc_array, axis=0)\n","    ci_val_acc = np.percentile(val_acc_array, [2.5, 97.5], axis=0)\n","    \n","    # Balanced accuracy on train set\n","    train_balanced_acc_array = np.array(train_balanced_acc_list).reshape(n_splits,epochs)\n","    mean_train_balanced_acc = np.mean(train_balanced_acc_array, axis=0)\n","    ci_train_balanced_acc = np.percentile(train_balanced_acc_array, [2.5, 97.5], axis=0)\n","\n","    # Balanced accuracy on validation set\n","    val_balanced_acc_array = np.array(val_balanced_acc_list).reshape(n_splits,epochs)\n","    mean_val_balanced_acc = np.mean(val_balanced_acc_array, axis=0)\n","    ci_val_balanced_acc = np.percentile(val_balanced_acc_array, [2.5, 97.5], axis=0)\n","\n","    # Create a DataFrame for Seaborn\n","    df_train_loss = pd.DataFrame({\n","            'Epochs': np.arange(epochs),\n","            'Mean_Train_Loss': mean_train_loss,\n","            'Lower_CI': ci_train_loss[0],\n","            'Upper_CI': ci_train_loss[1]})\n","\n","    df_val_loss = pd.DataFrame({\n","            'Epochs': np.arange(epochs),\n","            'Mean_Val_Loss': mean_val_loss,\n","            'Lower_CI': ci_val_loss[0],\n","            'Upper_CI': ci_val_loss[1]})\n","        \n","    df_train_acc = pd.DataFrame({\n","            'Epochs': np.arange(epochs),\n","            'Mean_Train_Acc': mean_train_acc,\n","            'Lower_CI': ci_train_acc[0],\n","            'Upper_CI': ci_train_acc[1]})\n","        \n","    df_val_acc = pd.DataFrame({\n","            'Epochs': np.arange(epochs),\n","            'Mean_Val_Acc': mean_val_acc,\n","            'Lower_CI': ci_val_acc[0],\n","            'Upper_CI': ci_val_acc[1]})\n","\n","    df_train_balanced_acc = pd.DataFrame({\n","        'Epochs': np.arange(epochs), \n","        'Mean_Train_Balanced_Acc': mean_train_balanced_acc,\n","        'Lower_CI': ci_train_balanced_acc[0],\n","        'Upper_CI': ci_train_balanced_acc[1]})\n","\n","    df_val_balanced_acc = pd.DataFrame({\n","        'Epochs': np.arange(epochs),\n","        'Mean_Val_Balanced_Acc': mean_val_balanced_acc,\n","        'Lower_CI': ci_val_balanced_acc[0],\n","        'Upper_CI': ci_val_balanced_acc[1]})\n","                                            \n","    dfs_train_loss[f'{cat}'] = df_train_loss\n","    dfs_val_loss[f'{cat}'] = df_val_loss\n","    dfs_train_acc[f'{cat}'] = df_train_acc \n","    dfs_val_acc[f'{cat}'] = df_val_acc  \n","    dfs_train_balanced_acc[f'{cat}'] = df_train_balanced_acc \n","    dfs_val_balanced_acc[f'{cat}'] = df_val_balanced_acc  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:35:27.266448Z","iopub.status.busy":"2023-12-21T22:35:27.266070Z","iopub.status.idle":"2023-12-21T22:35:30.824193Z","shell.execute_reply":"2023-12-21T22:35:30.823265Z","shell.execute_reply.started":"2023-12-21T22:35:27.266419Z"},"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharey = True)  \n","\n","# Sample iteration over the dictionary to plot subplots\n","for i, cat in enumerate(reflective_categories):\n","    df_train = dfs_train_loss[cat]\n","    df_val = dfs_val_loss[cat]\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Mean lineplot\n","    sns.pointplot(data=df_train, x='Epochs', y='Mean_Train_Loss', color='blue', ax = ax)\n","    sns.pointplot(data=df_val, x='Epochs', y='Mean_Val_Loss', color='orange', ax = ax) \n","    \n","    # Fill between the confidence interval\n","    ax.fill_between(df_train['Epochs'], df_train['Lower_CI'], df_train['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","    ax.fill_between(df_val['Epochs'], df_val['Lower_CI'], df_val['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","    \n","    #ax.set_xticks(np.arange(len(training_examples)), training_examples)\n","    ax.set_xlabel('Epochs')\n","    ax.set_ylabel(\"Loss\")\n","    ax.set_title(f\"{cat}\") \n","    ax.legend()\n","\n","fig.delaxes(axs[1,3])\n","plt.suptitle(f\"{n_splits}-fold CV Loss with 95% CI per class with bs : {batch_size}, lr : {learning_rate}, {epochs} epochs\")\n","plt.tight_layout()\n","plt.show()\n","\n","fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharey = True)  \n","\n","# Sample iteration over the dictionary to plot subplots\n","for i, cat in enumerate(reflective_categories):\n","    df_train = dfs_train_acc[cat]\n","    df_val = dfs_val_acc[cat]\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Mean lineplot\n","    sns.pointplot(data=df_train, x='Epochs', y='Mean_Train_Acc', color='blue', ax = ax)\n","    sns.pointplot(data=df_val, x='Epochs', y='Mean_Val_Acc', color='orange', ax = ax) \n","    \n","    # Fill between the confidence interval\n","    ax.fill_between(df_train['Epochs'], df_train['Lower_CI'], df_train['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","    ax.fill_between(df_val['Epochs'], df_val['Lower_CI'], df_val['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","    \n","    #ax.set_xticks(np.arange(len(training_examples)), training_examples)\n","    ax.set_xlabel('Epochs')\n","    ax.set_ylabel(\"Accuracy\")\n","    ax.set_title(f\"{cat}\") \n","    ax.legend()\n","    \n","fig.delaxes(axs[1,3])\n","plt.suptitle(f\"{n_splits}-fold CV Accuracy with 95% CI per class with bs : {batch_size}, lr : {learning_rate}, {epochs} epochs\")\n","plt.tight_layout()\n","plt.show()\n","\n","fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharey = True)  \n","\n","# Sample iteration over the dictionary to plot subplots\n","for i, cat in enumerate(reflective_categories):\n","    df_train = dfs_train_balanced_acc[cat]\n","    df_val = dfs_val_balanced_acc[cat]\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Mean lineplot\n","    sns.pointplot(data=df_train, x='Epochs', y='Mean_Train_Balanced_Acc', color='blue', ax = ax)\n","    sns.pointplot(data=df_val, x='Epochs', y='Mean_Val_Balanced_Acc', color='orange', ax = ax) \n","    \n","    # Fill between the confidence interval\n","    ax.fill_between(df_train['Epochs'], df_train['Lower_CI'], df_train['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","    ax.fill_between(df_val['Epochs'], df_val['Lower_CI'], df_val['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","    \n","    #ax.set_xticks(np.arange(len(training_examples)), training_examples)\n","    ax.set_xlabel('Epochs')\n","    ax.set_ylabel(\"Balanced Accuracy\")\n","    ax.set_title(f\"{cat}\") \n","    ax.legend()\n","    \n","fig.delaxes(axs[1,3])\n","plt.suptitle(f\"{n_splits}-fold CV Balanced Accuracy with 95% CI per class with bs : {batch_size}, lr : {learning_rate}, {epochs} epochs\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluate for each class\n","\n","Functions for the evaluation:\n","- prepare_test_dataset_for_binclf\n","- evaluate_bin\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T21:39:28.148416Z","iopub.status.busy":"2023-12-20T21:39:28.147533Z","iopub.status.idle":"2023-12-20T21:39:28.163913Z","shell.execute_reply":"2023-12-20T21:39:28.162960Z","shell.execute_reply.started":"2023-12-20T21:39:28.148379Z"},"trusted":true},"outputs":[],"source":["def prepare_test_dataset_for_binclf(df_sentences_test, batch_size):\n","\n","    df_test = pd.DataFrame()\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","    max_length_test = max(df_sentences_test['sentence'].apply(lambda sentence: len(sentence.split())))\n","    df_test['text'] = df_sentences_test['sentence'].apply(\n","            lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_test))\n","\n","    label_encoder_test = LabelEncoder()\n","    df_test['label'] = label_encoder_test.fit_transform(df_sentences_test['y'])\n","    #print(f\"Test data : {len(df_test)} sentences\")\n","\n","    # Create a custom dataset\n","    class CustomDataset(Dataset):\n","        def __init__(self, text, label):\n","            self.text = text\n","            self.label = label\n","        def __len__(self):\n","            return len(self.text)\n","        def __getitem__(self, idx):\n","            return {\n","                'text': torch.tensor(self.text[idx], dtype=torch.long),\n","                'label': torch.tensor(self.label[idx], dtype=torch.long)\n","            }\n","\n","    test_dataset = CustomDataset(df_test['text'].values, df_test['label'].values)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","    return test_loader, label_encoder_test\n","\n","#if freeze_weights:\n","#    # Freeze all layers except the last two\n","#    for param in model.parameters():\n","#        param.requires_grad = False\n","#    for param in model.classifier.parameters():\n","#        param.requires_grad = True\n","\n","#####################################\n","def evaluate_bin(model, test_loader, label_encoder, device, accuracy_metric):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    pred_confidence = []\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            inputs = batch['text'].to(device)\n","            labels = batch['label'].to(device)\n","            outputs = model(inputs)\n","            predictions = torch.argmax(outputs.logits, axis=1)\n","            all_preds.extend(predictions.cpu().numpy().tolist())\n","            all_labels.extend(labels.tolist())\n","            ### compute confidence score\n","            probabilities = torch.softmax(outputs.logits, dim=1)\n","            pred_confidence.extend(probabilities.max(dim=1).values.cpu().detach().numpy())  # Confidence scores\n","\n","    # compute accuracy\n","    accuracy = accuracy_metric.compute(predictions=all_preds, references=all_labels)[\"accuracy\"]\n","    # Decode label encodings\n","    predicted_labels = label_encoder.inverse_transform(all_preds)\n","    true_labels = label_encoder.inverse_transform(all_labels)\n","\n","    # Get unique labels from true and predicted labels and their union for the confusion matrix\n","    unique_true_labels = set(predicted_labels)\n","    unique_predicted_labels = set(true_labels)\n","    unique_labels_union = unique_true_labels.union(unique_predicted_labels)\n","\n","    class_labels = sorted(unique_labels_union)\n","\n","    return accuracy, class_labels, predicted_labels, true_labels, pred_confidence"]},{"cell_type":"markdown","metadata":{},"source":["for HP search"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load test dataset\n","#test_dataset_to_use = list_test_datasets['balanced_test_dataset_up'].copy()\n","print(f\"Length of test data : {len(original_test_dataset)}\")\n","sns.histplot(original_test_dataset['y'])\n","plt.title('Test Dataset')\n","plt.tick_params(axis='x',labelrotation = 45)\n","plt.tight_layout()\n","plt.show()\n","#fig, axs = plt.subplots(1, len(reflective_categories), figsize=(15, 4))\n","accuracy_data = {}\n","class_labels_data = {}\n","predicted_labels_data = {}\n","true_labels_data = {}\n","pred_confidence_data = {}\n","\n","for i, cat in enumerate(reflective_categories):\n","    # preprocess the test dataset for each case : each model has been trained for a binary clf\n","    print(f\"Evaluation for {cat}\")\n","    df_sentences_test_bin = original_test_dataset.copy()\n","    df_sentences_test_bin['y'] = np.where(df_sentences_test_bin['y'] == cat, cat, 'Other')\n","    #sns.histplot(df_sentences_test_bin['y'])\n","    #plt.show()\n","    \n","    test_loader, label_encoder_test = prepare_test_dataset_for_binclf(df_sentences_test_bin, batch_size) \n","    \n","    # Initialize the model: Take BINARY clf !!!\n","    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","\n","    # Load the state dictionary of the best model\n","    model.load_state_dict(best_model[cat])\n","\n","    # Evaluate the best model\n","    #accuracy, class_labels, predicted_labels, true_labels, pred_confidence = evaluate_bin(idx = i,\n","#                                                                 cat = cat,\n","#                                                                 model = model,\n","#                                                                 test_loader = test_loader,\n","#                                                                 label_encoder = label_encoder_test,\n","#                                                                 device = device,\n","#                                                                 plot_cm = False,\n","#                                                                 plot_cf = True,\n","#                                                                 accuracy_metric = load_metric(\"accuracy\"),\n","#                                                                 axs = axs)\n","    accuracy, class_labels, predicted_labels, true_labels, pred_confidence = evaluate_bin(model = model,\n","                                                                                test_loader = test_loader,\n","                                                                                label_encoder = label_encoder_test,\n","                                                                                device = device,\n","                                                                                accuracy_metric = load_metric(\"accuracy\"))\n","    \n","    # Store data for each category in the respective dictionaries\n","    accuracy_data[cat] = accuracy\n","    class_labels_data[cat] = class_labels\n","    predicted_labels_data[cat] = predicted_labels\n","    true_labels_data[cat] = true_labels\n","    pred_confidence_data[cat] = pred_confidence\n","\n","print(f\"\\nOverall accuracy of multiple binary clf : {np.mean(list(accuracy_data.values())).round(4)}\")\n","# Weighted average accuracy\n","weights = [len(original_test_dataset[original_test_dataset['y'] == cat]) for cat in reflective_categories]\n","# Calculate the weighted average\n","weighted_avg = np.round(sum(w * v for w, v in zip(weights, accuracy_data.values())) / sum(weights),4)\n","print(f\"\\nWeights : {weights}\")\n","print(f\"Weighted accuracy of multiple binary clf : {weighted_avg}\\n\\n\")    \n","\n","#plt.tight_layout()\n","#plt.show()\n","\n","predicted_labels_df = pd.DataFrame()\n","true_labels_df = pd.DataFrame()\n","pred_confidence_df = pd.DataFrame()\n","for cat in reflective_categories:\n","    predicted_labels_df[cat] = predicted_labels_data[cat]\n","    true_labels_df[cat] = true_labels_data[cat]\n","    pred_confidence_df[cat] = pred_confidence_data[cat]"]},{"cell_type":"markdown","metadata":{},"source":["for evaluation with 3 epochs and bs 8"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T21:24:23.400818Z","iopub.status.busy":"2023-12-20T21:24:23.399851Z","iopub.status.idle":"2023-12-20T21:24:23.760542Z","shell.execute_reply":"2023-12-20T21:24:23.759673Z","shell.execute_reply.started":"2023-12-20T21:24:23.400775Z"},"trusted":true},"outputs":[],"source":["# Select the reflective categories and show their distribution\n","reflective_cat_in_order = list(train_dataset[\"y\"].value_counts().sort_values(ascending=False).index)\n","reflective_cat_in_order_wo_other = [item for item in reflective_cat_in_order if item != 'Other']\n","print(f\"List of reflective categories in order : {reflective_cat_in_order}\")\n","print(f\"List of reflective categories in order without 'Other': {reflective_cat_in_order_wo_other}\")\n","\n","topN_classes = reflective_cat_in_order_wo_other[:8]\n","reflective_categories = topN_classes\n","print(f\"\\ntopN reflective categories: {reflective_categories}\")\n","\n","# Load test dataset\n","#test_dataset_to_use = list_test_datasets['balanced_test_dataset_up'].copy()\n","print(f\"Length of test data : {len(original_test_dataset)}\")\n","sns.histplot(original_test_dataset['y'])\n","plt.title('Test Dataset')\n","plt.tick_params(axis='x',labelrotation = 45)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T21:39:38.800675Z","iopub.status.busy":"2023-12-20T21:39:38.799815Z","iopub.status.idle":"2023-12-20T22:15:23.143091Z","shell.execute_reply":"2023-12-20T22:15:23.142149Z","shell.execute_reply.started":"2023-12-20T21:39:38.800643Z"},"trusted":true},"outputs":[],"source":["accuracy_data = {}\n","class_labels_data = {}\n","predicted_labels_data = {}\n","true_labels_data = {}\n","pred_confidence_data = {}\n","\n","# Define training parameters\n","batch_size, epochs, learning_rate = 8, 3, 2e-5\n","\n","for i, cat in enumerate(reflective_categories):\n","    print(f\"Training for {cat}\")\n","    # preprocess the test dataset for each category\n","    train_dataset_bin = train_dataset.copy()\n","    train_dataset_bin['y'] = np.where(train_dataset_bin['y'] == cat, cat, 'Other')\n","    test_dataset_bin = original_test_dataset.copy()\n","    test_dataset_bin['y'] = np.where(test_dataset_bin['y'] == cat, cat, 'Other')\n","    \n","    train_dataset_pp, test_dataset_pp, label_encoder_test = preprocess_data_train_test(train_dataset_bin, test_dataset_bin)\n","\n","    # Initialize the pre-trained BERT model\n","    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","    \n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset_pp, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset_pp, batch_size=batch_size)\n","\n","    # Set up optimizer and scheduler\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)\n","\n","    train_losses, avg_acc_per_epoch = train(model, train_loader, epochs, optimizer, scheduler, device, False)\n","    \n","    print(f\"Evaluation for {cat}\")\n","    accuracy, class_labels, predicted_labels, true_labels, pred_confidence = evaluate_bin(model = model,\n","                                                                                test_loader = test_loader,\n","                                                                                label_encoder = label_encoder_test,\n","                                                                                device = device,\n","                                                                                accuracy_metric = load_metric(\"accuracy\"))\n","    \n","    # Store data for each category in the respective dictionaries\n","    accuracy_data[cat] = accuracy\n","    class_labels_data[cat] = class_labels\n","    predicted_labels_data[cat] = predicted_labels\n","    true_labels_data[cat] = true_labels\n","    pred_confidence_data[cat] = pred_confidence\n","\n","print(f\"\\nOverall accuracy of multiple binary clf : {np.mean(list(accuracy_data.values())).round(4)}\")\n","# Weighted average accuracy\n","weights = [len(original_test_dataset[original_test_dataset['y'] == cat]) for cat in reflective_categories]\n","# Calculate the weighted average\n","weighted_avg = np.round(sum(w * v for w, v in zip(weights, accuracy_data.values())) / sum(weights),4)\n","print(f\"\\nWeights : {weights}\")\n","print(f\"Weighted accuracy of multiple binary clf : {weighted_avg}\\n\\n\")    \n","\n","predicted_labels_df = pd.DataFrame()\n","true_labels_df = pd.DataFrame()\n","pred_confidence_df = pd.DataFrame()\n","for cat in reflective_categories:\n","    predicted_labels_df[cat] = predicted_labels_data[cat]\n","    true_labels_df[cat] = true_labels_data[cat]\n","    pred_confidence_df[cat] = pred_confidence_data[cat]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:02:46.123019Z","iopub.status.busy":"2023-12-21T22:02:46.122144Z","iopub.status.idle":"2023-12-21T22:02:47.427378Z","shell.execute_reply":"2023-12-21T22:02:47.426079Z","shell.execute_reply.started":"2023-12-21T22:02:46.122968Z"},"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(2, 4, figsize=(15, 6)) \n","print(reflective_categories)\n","\n","for i, cat in enumerate(reflective_categories):\n","    ax = axs[i // 4, i % 4]\n","    # Create confusion matrix\n","    cm = confusion_matrix(true_labels_df[cat].values, predicted_labels_df[cat].values, labels=class_labels_data[cat])\n","    # Confusion Matrix\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels_data[cat], yticklabels=class_labels_data[cat], ax=ax)\n","    ax.set_xlabel(\"Predicted\")\n","    ax.set_ylabel(\"True\")\n","    ax.set_title(f\"{cat}, acc {np.round(accuracy_data[cat],3)}\")\n","    \n","fig.delaxes(axs[1, 3])\n","plt.suptitle(f\"Confusion matrices per class on test dataset\")\n","plt.tight_layout()\n","plt.show()\n","\n","fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharex = True, sharey = True) \n","\n","for i, cat in enumerate(reflective_categories):\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Confidence Scores Histogram\n","    #ax.hist(pred_confidence_df[cat], bins=50)\n","    correct_confidence = [pred_confidence_df[cat][i] for i in range(len(predicted_labels_df[cat])) if predicted_labels_df[cat][i] == true_labels_df[cat][i]]\n","    incorrect_confidence = [pred_confidence_df[cat][i] for i in range(len(predicted_labels_df[cat])) if predicted_labels_df[cat][i] != true_labels_df[cat][i]]\n","    ax.hist(correct_confidence, bins=50, color='green', alpha=0.7, label='Correct Predictions')\n","    ax.hist(incorrect_confidence, bins=50, color='red', alpha=0.7, label='Incorrect Predictions')\n","    ax.set_xlabel('Confidence score')\n","    ax.set_ylabel('Number of predictions')\n","    ax.set_title(f\"{cat}, acc {np.round(accuracy_data[cat],3)}\")\n","    ax.legend()\n","\n","fig.delaxes(axs[1, 3])\n","plt.suptitle(f\"Confidence scores per class on test dataset\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(predicted_labels_df['Experience'].unique())\n","print(true_labels_df['Experience'].unique())\n","print(reflective_categories)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T22:16:02.736946Z","iopub.status.busy":"2023-12-20T22:16:02.735978Z","iopub.status.idle":"2023-12-20T22:16:02.831315Z","shell.execute_reply":"2023-12-20T22:16:02.830295Z","shell.execute_reply.started":"2023-12-20T22:16:02.736906Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n","\n","# Initialize variables to store sum of metrics and count of classes\n","sum_accuracy = 0.0\n","sum_weighted_accuracy = 0.0\n","sum_f1 = 0.0\n","sum_auc = 0.0\n","count_classes = 0\n","\n","# Iterate over each 'cat'\n","for cat in reflective_categories:\n","    predicted_labels = predicted_labels_df[cat].values\n","    true_labels = true_labels_df[cat].values\n","    \n","    # Encode labels\n","    label_encoder = LabelEncoder()\n","    true_labels_encoded = label_encoder.fit_transform(true_labels)\n","    predicted_labels_encoded = label_encoder.transform(predicted_labels)\n","    \n","    # Calculate metrics\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    balanced_accuracy = balanced_accuracy_score(true_labels, predicted_labels)\n","    #f1 = f1_score(true_labels, predicted_labels, labels = [cat, 'Other'], pos_label = cat)\n","    f1_scores = f1_score(true_labels_encoded, predicted_labels_encoded, pos_label=label_encoder.transform([cat])[0])\n","    #auc = roc_auc_score(true_labels, predicted_labels) if len(set(true_labels)) > 1 else None  # AUC requires both classes\n","    auc = roc_auc_score(true_labels_encoded, predicted_labels_encoded) if len(set(true_labels_encoded)) > 1 else None\n","    \n","     # Sum metrics\n","    sum_accuracy += accuracy\n","    sum_weighted_accuracy += balanced_accuracy\n","    sum_f1 += f1_scores\n","    if auc is not None:\n","        sum_auc += auc\n","        \n","    # Increment count of classes\n","    count_classes += 1\n","    \n","    # Print metrics for the current class\n","    print(f\"Overall accuracy for class '{cat}' = {accuracy:.4f}\")\n","    print(f\"Balanced accuracy for class '{cat}' = {balanced_accuracy:.4f}\")\n","    print(f\"F1 score for class '{cat}' = {f1_scores:.4f}\")\n","    if auc is not None:\n","        print(f\"AUC for class '{cat}' = {auc:.4f}\")\n","    else:\n","        print(f\"AUC for class '{cat}' cannot be computed due to insufficient data\")\n","    print(\"--------------------------------------\")\n","\n","# Calculate averages\n","avg_accuracy = sum_accuracy / count_classes if count_classes > 0 else 0.0\n","avg_weighted_accuracy = sum_weighted_accuracy / count_classes if count_classes > 0 else 0.0\n","avg_f1 = sum_f1 / count_classes if count_classes > 0 else 0.0\n","avg_auc = sum_auc / count_classes if count_classes > 0 else None\n","\n","# Print average metrics\n","print(\"#########################################\")\n","print(\"############## AVERAGE ##################\")\n","print(\"#########################################\")\n","print(f\"Average accuracy across classes = {avg_accuracy:.4f}\")\n","print(f\"Average weighted accuracy across classes = {avg_weighted_accuracy:.4f}\")\n","print(f\"Average F1 score across classes = {avg_f1:.4f}\")\n","if avg_auc is not None:\n","    print(f\"Average AUC across classes = {avg_auc:.4f}\")\n","else:\n","    print(\"Average AUC across classes cannot be computed due to insufficient data\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for cat in reflective_categories:\n","    print(f\"\\npredicted_labels_{cat.lower()} = {predicted_labels_df[cat].values}\\n\")\n","        \n","for cat in reflective_categories:\n","    print(f\"\\ntrue_labels_{cat.lower()} = {true_labels_df[cat].values}\\n\")\n","        \n","for cat in reflective_categories:\n","    print(f\"\\npred_confidence_{cat.lower()} = {pred_confidence_df[cat].values}\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluate with Cascaded binary classifiers"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cascaded_clf_classes_ordered = ['Intention', 'Learning', 'Perspective', 'Difficulty', 'Belief', 'Feeling', 'Experience']\n","\n","# test_datasets = {\"original_test_dataset\": original_test_dataset, \n","#                  \"balanced_test_dataset_down\": balanced_test_dataset_down, \n","#                  \"balanced_test_dataset_up\": balanced_test_dataset_up, \n","#                  \"small_balanced_test_dataset_up\": small_balanced_test_dataset_up}\n","\n","test_dataset_cascaded = list_test_datasets['balanced_test_dataset'].copy()\n","print(f\"Length of test data : {len(test_dataset_cascaded)}\")\n","sns.histplot(test_dataset_cascaded['y'])\n","plt.title('Test Dataset')\n","plt.tick_params(axis='x',labelrotation = 45)\n","plt.tight_layout()\n","plt.show()\n","test_dataset_cascaded.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Start of the cascaded evaluation\")\n","\n","accuracy_data = {}\n","class_labels_data = {}\n","predicted_labels_data = {}\n","true_labels_data = {}\n","pred_confidence_data = {}\n","all_preds = []\n","all_true_labels = []\n","\n","for cat in cascaded_clf_classes_ordered:\n","    # preprocess the test dataset for each case : each model has been trained for a binary clf\n","    print(f\"Evaluation for {cat}\")\n","    df_sentences_test_bin = test_dataset_cascaded.reset_index()\n","    df_sentences_test_bin['y'] = np.where(df_sentences_test_bin['y'] == cat, cat, 'Other')\n","    #sns.histplot(df_sentences_test_bin['y'])\n","    #plt.show()\n","    \n","    test_loader, label_encoder_test = prepare_test_dataset_for_binclf(df_sentences_test_bin, batch_size) \n","    \n","    # Initialize the model\n","    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=9).to(device)\n","\n","    # Load the state dictionary of the best model\n","    model.load_state_dict(best_model[cat])\n","    \n","    accuracy, class_labels, predicted_labels, true_labels, pred_confidence = evaluate_bin(model = model,\n","                                                                                test_loader = test_loader,\n","                                                                                label_encoder = label_encoder_test,\n","                                                                                device = device,\n","                                                                                accuracy_metric = load_metric(\"accuracy\"))\n","    \n","    indices_to_remove = [pos for pos in range(len(predicted_labels)) if predicted_labels[pos] == cat]\n","    all_true_labels.extend(test_dataset_cascaded.iloc[indices_to_remove]['y'])\n","    test_dataset_cascaded.drop(test_dataset_cascaded.index[indices_to_remove], inplace=True)\n","    print(f\"Length test dataset after eval {cat}: {len(test_dataset_cascaded)}\")\n","    \n","    #all_true_labels.extend()\n","    all_preds.extend(predicted_labels)\n","    # Store data for each category in the respective dictionaries\n","    accuracy_data[cat] = accuracy\n","    class_labels_data[cat] = class_labels\n","    predicted_labels_data[cat] = predicted_labels\n","    true_labels_data[cat] = true_labels\n","    pred_confidence_data[cat] = pred_confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(all_true_labels)\n","print(all_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cascaded_clf_classes_ordered.append('Other')\n","class_labels = cascaded_clf_classes_ordered\n","\n","true_labels = all_true_labels\n","predicted_labels = all_preds\n","\n","# Generate classification report\n","report = classification_report(true_labels, predicted_labels, zero_division = 1, target_names=class_labels)\n","print(report)\n","\n","# Create confusion matrix\n","cm = confusion_matrix(true_labels, predicted_labels, labels=class_labels)\n","\n","fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n","# Subplot 1: Confusion Matrix\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels, ax=axs[0])\n","axs[0].set_xlabel(\"Predicted\")\n","axs[0].set_ylabel(\"True\")\n","axs[0].set_title(\"Confusion Matrix\")\n","\n","        # Subplot 2: Confidence Scores Histogram\n","        #axs[1].hist(pred_confidence, bins=50)\n","        #axs[1].set_xlabel('Confidence score')\n","        #axs[1].set_ylabel('Number of predictions')\n","        #axs[1].set_title('Confidence score of predictions')\n","        \n","        # Subplot 3: Confidence Scores Histogram for Correct and Incorrect Predictions\n","correct_confidence = [pred_confidence[i] for i in range(len(predicted_labels)) if predicted_labels[i] == true_labels[i]]\n","incorrect_confidence = [pred_confidence[i] for i in range(len(predicted_labels)) if predicted_labels[i] != true_labels[i]]\n","axs[1].hist(correct_confidence, bins=50, color='green', alpha=0.7, label='Correct Predictions')\n","axs[1].hist(incorrect_confidence, bins=50, color='red', alpha=0.7, label='Incorrect Predictions')\n","axs[1].set_xlabel('Confidence score')\n","axs[1].set_ylabel('Number of predictions')\n","axs[1].set_title('Confidence score of predictions')\n","axs[1].legend()\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","# Pipeline self-learning for each category\n","- **Step 1:** \n","    - option A : downsample the train dataset and create 8 dataset with binary classes for each\n","    - option B : Create the downsampled (25/75 and equal distrib of other classes) datasets for each class\n","\n","- **Step 2:** Train with CV with downsampled datasets --> with optimal number of epochs (2-3 epochs)\n","    - compare accuracy compared to initial multiclass clf\n","    - Look at correlation between confidence score and accuracy\n","\n","\n","- **Step 3:** Plot learning curves for each class with good number of epochs and the corresponding dataset\n","\n","### 1) Downsampling\n","- Create balanced datasets with downsampling"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T22:31:36.496653Z","iopub.status.busy":"2023-12-20T22:31:36.495757Z","iopub.status.idle":"2023-12-20T22:31:36.510957Z","shell.execute_reply":"2023-12-20T22:31:36.509932Z","shell.execute_reply.started":"2023-12-20T22:31:36.496615Z"},"trusted":true},"outputs":[],"source":["from imblearn.under_sampling import RandomUnderSampler\n","\n","df_sentences = train_dataset\n","\n","topN = 8\n","reflective_cat_in_order = list(df_sentences[\"y\"].value_counts().sort_values(ascending=False).index)\n","topN_classes = reflective_cat_in_order[:topN]\n","print(f\"\\nList of reflective categories in order : {reflective_cat_in_order}\")\n","print(f\"List of topN selected categories for downsampling : {topN_classes}\")\n","\n","M_catType = CategoricalDtype(categories = topN_classes, ordered = True)\n","df_sentences['y'] = df_sentences['y'].astype(M_catType)\n","\n","dict_categories_ordered = dict(df_sentences[\"y\"].value_counts().sort_values(ascending=False))\n","df_sentences_topN_classes = df_sentences[df_sentences['y'].isin(topN_classes)]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:04:27.218436Z","iopub.status.busy":"2023-12-21T22:04:27.217707Z","iopub.status.idle":"2023-12-21T22:04:27.227201Z","shell.execute_reply":"2023-12-21T22:04:27.225969Z","shell.execute_reply.started":"2023-12-21T22:04:27.218400Z"},"trusted":true},"outputs":[],"source":["from imblearn.under_sampling import RandomUnderSampler\n","import pandas as pd\n","\n","def downsample_dataset(df, max_values):\n","    label_counts = dict(df[\"y\"].value_counts().sort_values(ascending=False))\n","\n","    downsampled_label_counts = label_counts\n","    for key, value in label_counts.items():\n","        downsampled_label_counts[key] = value if value < max_values else max_values\n","\n","    # Downsample to the maximum desired labels per class\n","    under_sampler = RandomUnderSampler(sampling_strategy= downsampled_label_counts)\n","    df_downsampled, _ = under_sampler.fit_resample(df, df['y'])\n","\n","    # sample the dataset randomly\n","    df_downsampled = df_downsampled.sample(frac = 1)\n","    print(f\"Length of the downsampled dataframe: {len(df_downsampled)}\")\n","    \n","    sns.histplot(df_downsampled['y'])\n","    plt.xticks(rotation = 45)\n","    plt.title(f\"Dataset downsampled - cut {max_values} samples\")\n","    plt.show()\n","\n","    return df_downsampled"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:36:04.314719Z","iopub.status.busy":"2023-12-21T22:36:04.314339Z","iopub.status.idle":"2023-12-21T22:36:04.656764Z","shell.execute_reply":"2023-12-21T22:36:04.655779Z","shell.execute_reply.started":"2023-12-21T22:36:04.314687Z"},"trusted":true},"outputs":[],"source":["train_dataset_downsampled = downsample_dataset(train_dataset, 400)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:04:41.570137Z","iopub.status.busy":"2023-12-21T22:04:41.569374Z","iopub.status.idle":"2023-12-21T22:04:41.814555Z","shell.execute_reply":"2023-12-21T22:04:41.813560Z","shell.execute_reply.started":"2023-12-21T22:04:41.570099Z"},"trusted":true},"outputs":[],"source":["test_dataset_downsampled = downsample_dataset(original_test_dataset, 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T20:00:03.030970Z","iopub.status.busy":"2023-12-18T20:00:03.029935Z","iopub.status.idle":"2023-12-18T20:00:03.386659Z","shell.execute_reply":"2023-12-18T20:00:03.385671Z","shell.execute_reply.started":"2023-12-18T20:00:03.030925Z"},"trusted":true},"outputs":[],"source":["dataset_downsampled = downsample_dataset(merged_df, 400)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#fig, axs = plt.subplots(2, 4, figsize = (15,6), sharey = True)\n","#for i, label in enumerate(topN_classes):\n","#    #print(label)\n","#    ax = axs[i//4, i%4]\n","#    sns.histplot(balanced_datasets[label]['y'], ax = ax)\n","#    ax.patches[topN_classes.index(label)].set_facecolor('red')\n","#    ax.set_title(f\"Dataset {label}, {len(balanced_datasets[label])}\")\n","#    ax.tick_params(axis='x',labelrotation = 45)\n","#plt.tight_layout()\n","#plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### 2) Train multiple binary CLF with the downsampled datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:35:51.361368Z","iopub.status.busy":"2023-12-21T22:35:51.361000Z","iopub.status.idle":"2023-12-21T22:35:51.658399Z","shell.execute_reply":"2023-12-21T22:35:51.657527Z","shell.execute_reply.started":"2023-12-21T22:35:51.361338Z"},"trusted":true},"outputs":[],"source":["reflective_cat_in_order = list(train_dataset_downsampled[\"y\"].value_counts().sort_values(ascending=False).index)\n","reflective_cat_in_order_wo_other = [item for item in reflective_cat_in_order if item != 'Other']\n","\n","topN_classes = reflective_cat_in_order_wo_other[:1]\n","reflective_categories = topN_classes\n","print(f\"\\ntopN reflective categories without other: {reflective_categories}\")\n","\n","test_dataset_downsampled = downsample_dataset(original_test_dataset, 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:36:22.858107Z","iopub.status.busy":"2023-12-21T22:36:22.857657Z","iopub.status.idle":"2023-12-21T22:38:13.447451Z","shell.execute_reply":"2023-12-21T22:38:13.446478Z","shell.execute_reply.started":"2023-12-21T22:36:22.858075Z"},"trusted":true},"outputs":[],"source":["%%time\n","print(\"After downsampling:\")\n","print(f\"Length of train dataset: {len(train_dataset_downsampled)}\")\n","print(f\"Length of test dataset: {len(test_dataset_downsampled)}\")\n","# Set hyperparameters\n","batch_size = 8\n","epochs = 4\n","learning_rate = 2e-5\n","n_splits = 2\n","\n","dfs_train_loss = {}\n","dfs_train_acc = {}\n","dfs_train_balanced_acc = {}\n","dfs_val_loss = {}\n","dfs_val_acc = {}\n","dfs_val_balanced_acc = {}\n","best_model = {}\n","\n","\n","print(f\"\\n\\nLaunching {n_splits}-fold CV per class with : {reflective_categories}\")\n","\n","for i, cat in enumerate(reflective_categories):\n","    print(f\"\\n\\nCV for {cat}\")\n","    train_loss_list = []\n","    train_acc_list = []\n","    train_balanced_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","    val_balanced_acc_list = []\n","    df_sentences_bin = train_dataset_downsampled.iloc[:1000].copy()\n","    df_sentences_bin['y'] = np.where(df_sentences_bin['y'] == cat, cat, 'Other')\n","    \n","    train_loss_list, val_loss_list, train_acc_list, train_balanced_acc_list, val_acc_list, val_balanced_acc_list, label_encoder_test, _, best_model[cat] = cross_validate_bin(df_sentences_train=df_sentences_bin,\n","                                                                                                df_sentences_test = test_dataset_downsampled,\n","                                                                                                freeze_weights=False, \n","                                                                                                batch_size=batch_size, \n","                                                                                                epochs=epochs, \n","                                                                                                learning_rate=learning_rate,\n","                                                                                                n_splits=n_splits,\n","                                                                                                train_loss_list = train_loss_list,\n","                                                                                                train_acc_list = train_acc_list,\n","                                                                                                train_balanced_acc_list = train_balanced_acc_list,\n","                                                                                                val_loss_list = val_loss_list,\n","                                                                                                val_acc_list = val_acc_list,\n","                                                                                                val_balanced_acc_list = val_balanced_acc_list,\n","                                                                                                device = device)\n","\n","    # loss on training set\n","    train_loss_array = np.array(train_loss_list).reshape(n_splits,epochs)\n","    mean_train_loss = np.mean(train_loss_array, axis=0)\n","    ci_train_loss = np.percentile(train_loss_array, [2.5, 97.5], axis=0)\n","\n","    # loss on validation set\n","    val_loss_array = np.array(val_loss_list).reshape(n_splits,epochs)\n","    mean_val_loss = np.mean(val_loss_array, axis=0)\n","    ci_val_loss = np.percentile(val_loss_array, [2.5, 97.5], axis=0)\n","    \n","    # accuracy on training set\n","    train_acc_array = np.array(train_acc_list).reshape(n_splits,epochs)\n","    mean_train_acc = np.mean(train_acc_array, axis=0)\n","    ci_train_acc = np.percentile(train_acc_array, [2.5, 97.5], axis=0)\n","        \n","    # accuracy on validation set\n","    val_acc_array = np.array(val_acc_list).reshape(n_splits,epochs)\n","    mean_val_acc = np.mean(val_acc_array, axis=0)\n","    ci_val_acc = np.percentile(val_acc_array, [2.5, 97.5], axis=0)\n","    \n","    # Balanced accuracy on train set\n","    train_balanced_acc_array = np.array(train_balanced_acc_list).reshape(n_splits,epochs)\n","    mean_train_balanced_acc = np.mean(train_balanced_acc_array, axis=0)\n","    ci_train_balanced_acc = np.percentile(train_balanced_acc_array, [2.5, 97.5], axis=0)\n","\n","    # Balanced accuracy on validation set\n","    val_balanced_acc_array = np.array(val_balanced_acc_list).reshape(n_splits,epochs)\n","    mean_val_balanced_acc = np.mean(val_balanced_acc_array, axis=0)\n","    ci_val_balanced_acc = np.percentile(val_balanced_acc_array, [2.5, 97.5], axis=0)\n","\n","    # Create a DataFrame for Seaborn\n","    df_train_loss = pd.DataFrame({\n","            'Epochs': np.arange(epochs),\n","            'Mean_Train_Loss': mean_train_loss,\n","            'Lower_CI': ci_train_loss[0],\n","            'Upper_CI': ci_train_loss[1]})\n","\n","    df_val_loss = pd.DataFrame({\n","            'Epochs': np.arange(epochs),\n","            'Mean_Val_Loss': mean_val_loss,\n","            'Lower_CI': ci_val_loss[0],\n","            'Upper_CI': ci_val_loss[1]})\n","        \n","    df_train_acc = pd.DataFrame({\n","            'Epochs': np.arange(epochs),\n","            'Mean_Train_Acc': mean_train_acc,\n","            'Lower_CI': ci_train_acc[0],\n","            'Upper_CI': ci_train_acc[1]})\n","        \n","    df_val_acc = pd.DataFrame({\n","            'Epochs': np.arange(epochs),\n","            'Mean_Val_Acc': mean_val_acc,\n","            'Lower_CI': ci_val_acc[0],\n","            'Upper_CI': ci_val_acc[1]})\n","\n","    df_train_balanced_acc = pd.DataFrame({\n","        'Epochs': np.arange(epochs), \n","        'Mean_Train_Balanced_Acc': mean_train_balanced_acc,\n","        'Lower_CI': ci_train_balanced_acc[0],\n","        'Upper_CI': ci_train_balanced_acc[1]})\n","\n","    df_val_balanced_acc = pd.DataFrame({\n","        'Epochs': np.arange(epochs),\n","        'Mean_Val_Balanced_Acc': mean_val_balanced_acc,\n","        'Lower_CI': ci_val_balanced_acc[0],\n","        'Upper_CI': ci_val_balanced_acc[1]})\n","                                            \n","    dfs_train_loss[f'{cat}'] = df_train_loss\n","    dfs_val_loss[f'{cat}'] = df_val_loss\n","    dfs_train_acc[f'{cat}'] = df_train_acc \n","    dfs_val_acc[f'{cat}'] = df_val_acc  \n","    dfs_train_balanced_acc[f'{cat}'] = df_train_balanced_acc \n","    dfs_val_balanced_acc[f'{cat}'] = df_val_balanced_acc  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:38:38.491672Z","iopub.status.busy":"2023-12-21T22:38:38.490796Z","iopub.status.idle":"2023-12-21T22:38:42.007557Z","shell.execute_reply":"2023-12-21T22:38:42.006540Z","shell.execute_reply.started":"2023-12-21T22:38:38.491635Z"},"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharey = True)  \n","\n","# Sample iteration over the dictionary to plot subplots\n","for i, cat in enumerate(reflective_categories):\n","    df_train = dfs_train_loss[cat]\n","    df_val = dfs_val_loss[cat]\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Mean lineplot\n","    sns.pointplot(data=df_train, x='Epochs', y='Mean_Train_Loss', color='blue', ax = ax)\n","    sns.pointplot(data=df_val, x='Epochs', y='Mean_Val_Loss', color='orange', ax = ax) \n","    \n","    # Fill between the confidence interval\n","    ax.fill_between(df_train['Epochs'], df_train['Lower_CI'], df_train['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","    ax.fill_between(df_val['Epochs'], df_val['Lower_CI'], df_val['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","    \n","    #ax.set_xticks(np.arange(len(training_examples)), training_examples)\n","    ax.set_xlabel('Epochs')\n","    ax.set_ylabel(\"Loss\")\n","    ax.set_title(f\"{cat}\") \n","    ax.legend()\n","\n","fig.delaxes(axs[1,3])\n","plt.suptitle(f\"{n_splits}-fold CV Loss with 95% CI per class with bs : {batch_size}, lr : {learning_rate}, {epochs} epochs\")\n","plt.tight_layout()\n","plt.show()\n","\n","fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharey = True)  \n","\n","# Sample iteration over the dictionary to plot subplots\n","for i, cat in enumerate(reflective_categories):\n","    df_train = dfs_train_acc[cat]\n","    df_val = dfs_val_acc[cat]\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Mean lineplot\n","    sns.pointplot(data=df_train, x='Epochs', y='Mean_Train_Acc', color='blue', ax = ax)\n","    sns.pointplot(data=df_val, x='Epochs', y='Mean_Val_Acc', color='orange', ax = ax) \n","    \n","    # Fill between the confidence interval\n","    ax.fill_between(df_train['Epochs'], df_train['Lower_CI'], df_train['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","    ax.fill_between(df_val['Epochs'], df_val['Lower_CI'], df_val['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","    \n","    #ax.set_xticks(np.arange(len(training_examples)), training_examples)\n","    ax.set_xlabel('Epochs')\n","    ax.set_ylabel(\"Accuracy\")\n","    ax.set_title(f\"{cat}\") \n","    ax.legend()\n","    \n","fig.delaxes(axs[1,3])\n","plt.suptitle(f\"{n_splits}-fold CV Accuracy with 95% CI per class with bs : {batch_size}, lr : {learning_rate}, {epochs} epochs\")\n","plt.tight_layout()\n","plt.show()\n","\n","\n","fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharey = True) \n","# Sample iteration over the dictionary to plot subplots\n","for i, cat in enumerate(reflective_categories):\n","    df_train = dfs_train_balanced_acc[cat]\n","    df_val = dfs_val_balanced_acc[cat]\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Mean lineplot\n","    sns.pointplot(data=df_train, x='Epochs', y='Mean_Train_Balanced_Acc', color='blue', ax = ax)\n","    sns.pointplot(data=df_val, x='Epochs', y='Mean_Val_Balanced_Acc', color='orange', ax = ax) \n","    \n","    # Fill between the confidence interval\n","    ax.fill_between(df_train['Epochs'], df_train['Lower_CI'], df_train['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","    ax.fill_between(df_val['Epochs'], df_val['Lower_CI'], df_val['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","    \n","    #ax.set_xticks(np.arange(len(training_examples)), training_examples)\n","    ax.set_xlabel('Epochs')\n","    ax.set_ylabel(\"Balanced Accuracy\")\n","    ax.set_title(f\"{cat}\") \n","    ax.legend()\n","    \n","fig.delaxes(axs[1,3])\n","plt.suptitle(f\"{n_splits}-fold CV Balanced Accuracy with 95% CI per class with bs : {batch_size}, lr : {learning_rate}, {epochs} epochs\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate after HP search 3 epochs, bs 8"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T22:36:49.982458Z","iopub.status.busy":"2023-12-20T22:36:49.982055Z","iopub.status.idle":"2023-12-20T22:52:38.505438Z","shell.execute_reply":"2023-12-20T22:52:38.504548Z","shell.execute_reply.started":"2023-12-20T22:36:49.982411Z"},"trusted":true},"outputs":[],"source":["accuracy_data = {}\n","class_labels_data = {}\n","predicted_labels_data = {}\n","true_labels_data = {}\n","pred_confidence_data = {}\n","\n","# Define training parameters\n","batch_size, epochs, learning_rate = 8, 3, 2e-5\n","\n","for i, cat in enumerate(reflective_categories):\n","    print(f\"\\nTraining for {cat}\")\n","    # preprocess the test dataset for each category\n","    train_dataset_bin = train_dataset_downsampled.copy()\n","    train_dataset_bin['y'] = np.where(train_dataset_bin['y'] == cat, cat, 'Other')\n","    test_dataset_bin = test_dataset_downsampled.copy()\n","    test_dataset_bin['y'] = np.where(test_dataset_bin['y'] == cat, cat, 'Other')\n","    \n","    train_dataset_pp, test_dataset_pp, label_encoder_test = preprocess_data_train_test(train_dataset_bin, test_dataset_bin)\n","\n","    # Initialize the pre-trained BERT model\n","    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","    \n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset_pp, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset_pp, batch_size=batch_size)\n","\n","    # Set up optimizer and scheduler\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)\n","\n","    train_losses, avg_acc_per_epoch = train(model, train_loader, epochs, optimizer, scheduler, device, False)\n","    \n","    print(f\"Evaluation for {cat}\")\n","    accuracy, class_labels, predicted_labels, true_labels, pred_confidence = evaluate_bin(model = model,\n","                                                                                test_loader = test_loader,\n","                                                                                label_encoder = label_encoder_test,\n","                                                                                device = device,\n","                                                                                accuracy_metric = load_metric(\"accuracy\"))\n","    \n","    # Store data for each category in the respective dictionaries\n","    accuracy_data[cat] = accuracy\n","    class_labels_data[cat] = class_labels\n","    predicted_labels_data[cat] = predicted_labels\n","    true_labels_data[cat] = true_labels\n","    pred_confidence_data[cat] = pred_confidence\n","\n","print(f\"\\nOverall accuracy of multiple binary clf : {np.mean(list(accuracy_data.values())).round(4)}\")\n","# Weighted average accuracy\n","weights = [len(original_test_dataset[original_test_dataset['y'] == cat]) for cat in reflective_categories]\n","# Calculate the weighted average\n","weighted_avg = np.round(sum(w * v for w, v in zip(weights, accuracy_data.values())) / sum(weights),4)\n","print(f\"\\nWeights : {weights}\")\n","print(f\"Weighted accuracy of multiple binary clf : {weighted_avg}\\n\\n\")    \n","\n","predicted_labels_df = pd.DataFrame()\n","true_labels_df = pd.DataFrame()\n","pred_confidence_df = pd.DataFrame()\n","for cat in reflective_categories:\n","    predicted_labels_df[cat] = predicted_labels_data[cat]\n","    true_labels_df[cat] = true_labels_data[cat]\n","    pred_confidence_df[cat] = pred_confidence_data[cat]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T23:00:12.161826Z","iopub.status.busy":"2023-12-20T23:00:12.160979Z","iopub.status.idle":"2023-12-20T23:00:12.209093Z","shell.execute_reply":"2023-12-20T23:00:12.207757Z","shell.execute_reply.started":"2023-12-20T23:00:12.161792Z"},"trusted":true},"outputs":[],"source":["print(class_labels_data['Feeling'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T22:58:51.361804Z","iopub.status.busy":"2023-12-20T22:58:51.361384Z","iopub.status.idle":"2023-12-20T22:58:52.614818Z","shell.execute_reply":"2023-12-20T22:58:52.613448Z","shell.execute_reply.started":"2023-12-20T22:58:51.361773Z"},"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(2, 4, figsize=(15, 6)) \n","print(reflective_categories)\n","\n","for i, cat in enumerate(reflective_categories):\n","    ax = axs[i // 4, i % 4]\n","    # Create confusion matrix\n","    cm = confusion_matrix(true_labels_df[cat].values, predicted_labels_df[cat].values, labels=class_labels_data[cat])\n","    # Confusion Matrix\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels_data[cat], yticklabels=class_labels_data[cat], ax=ax)\n","    ax.set_xlabel(\"Predicted\")\n","    ax.set_ylabel(\"True\")\n","    ax.set_title(f\"{cat}, acc {np.round(accuracy_data[cat],3)}\")\n","    \n","fig.delaxes(axs[1, 3])\n","plt.suptitle(f\"Confusion matrices per class on test dataset\")\n","plt.tight_layout()\n","plt.show()\n","\n","fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharex = True, sharey = True) \n","\n","for i, cat in enumerate(reflective_categories):\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Confidence Scores Histogram\n","    #ax.hist(pred_confidence_df[cat], bins=50)\n","    correct_confidence = [pred_confidence_df[cat][i] for i in range(len(predicted_labels_df[cat])) if predicted_labels_df[cat][i] == true_labels_df[cat][i]]\n","    incorrect_confidence = [pred_confidence_df[cat][i] for i in range(len(predicted_labels_df[cat])) if predicted_labels_df[cat][i] != true_labels_df[cat][i]]\n","    ax.hist(correct_confidence, bins=50, color='green', alpha=0.7, label='Correct Predictions')\n","    ax.hist(incorrect_confidence, bins=50, color='red', alpha=0.7, label='Incorrect Predictions')\n","    ax.set_xlabel('Confidence score')\n","    ax.set_ylabel('Number of predictions')\n","    ax.set_title(f\"{cat}, acc {np.round(accuracy_data[cat],3)}\")\n","    ax.legend()\n","\n","fig.delaxes(axs[1, 3])\n","plt.suptitle(f\"Confidence scores per class on test dataset\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Evaluate**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T22:55:40.835190Z","iopub.status.busy":"2023-12-20T22:55:40.834789Z","iopub.status.idle":"2023-12-20T22:55:42.437853Z","shell.execute_reply":"2023-12-20T22:55:42.436529Z","shell.execute_reply.started":"2023-12-20T22:55:40.835162Z"},"trusted":true},"outputs":[],"source":["print(f\"Length of test data : {len(test_dataset_downsampled)}\")\n","sns.histplot(test_dataset_downsampled['y'])\n","plt.title('Test Dataset')\n","plt.tick_params(axis='x',labelrotation = 45)\n","plt.tight_layout()\n","plt.show()\n","\n","print(reflective_categories)\n","accuracy_data = {}\n","class_labels_data = {}\n","predicted_labels_data = {}\n","true_labels_data = {}\n","pred_confidence_data = {}\n","\n","for i, cat in enumerate(reflective_categories):\n","    # preprocess the test dataset for each case : each model has been trained for a binary clf\n","    print(f\"Evaluation for {cat}\")\n","    df_sentences_test_bin = test_dataset_downsampled.copy()\n","    df_sentences_test_bin['y'] = np.where(df_sentences_test_bin['y'] == cat, cat, 'Other')\n","    \n","    test_loader, label_encoder_test = prepare_test_dataset_for_binclf(df_sentences_test_bin, batch_size) \n","    \n","    # Initialize the model: Take BINARY clf !!!\n","    model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","\n","    # Load the state dictionary of the best model\n","    model.load_state_dict(best_model[cat])\n","\n","    accuracy, class_labels, predicted_labels, true_labels, pred_confidence = evaluate_bin(model = model,\n","                                                                                test_loader = test_loader,\n","                                                                                label_encoder = label_encoder_test,\n","                                                                                device = device,\n","                                                                                accuracy_metric = load_metric(\"accuracy\"))\n","    # Store data for each category in the respective dictionaries\n","    accuracy_data[cat] = accuracy\n","    class_labels_data[cat] = class_labels\n","    predicted_labels_data[cat] = predicted_labels\n","    true_labels_data[cat] = true_labels\n","    pred_confidence_data[cat] = pred_confidence\n","\n","print(f\"\\nOverall accuracy of multiple binary clf : {np.mean(list(accuracy_data.values())).round(4)}\")\n","# Weighted average accuracy\n","weights = [len(test_dataset_downsampled[test_dataset_downsampled['y'] == cat]) for cat in reflective_categories]\n","# Calculate the weighted average\n","weighted_avg = np.round(sum(w * v for w, v in zip(weights, accuracy_data.values())) / sum(weights),4)\n","print(f\"\\nWeights : {weights}\")\n","print(f\"Weighted accuracy of multiple binary clf : {weighted_avg}\\n\\n\")    \n","\n","#plt.tight_layout()\n","#plt.show()\n","\n","predicted_labels_df = pd.DataFrame()\n","true_labels_df = pd.DataFrame()\n","pred_confidence_df = pd.DataFrame()\n","for cat in reflective_categories:\n","    predicted_labels_df[cat] = predicted_labels_data[cat]\n","    true_labels_df[cat] = true_labels_data[cat]\n","    pred_confidence_df[cat] = pred_confidence_data[cat]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T22:56:04.438959Z","iopub.status.busy":"2023-12-20T22:56:04.438564Z","iopub.status.idle":"2023-12-20T22:56:05.618758Z","shell.execute_reply":"2023-12-20T22:56:05.617615Z","shell.execute_reply.started":"2023-12-20T22:56:04.438926Z"},"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(2, 4, figsize=(15, 6)) \n","print(reflective_categories)\n","\n","for i, cat in enumerate(reflective_categories):\n","    ax = axs[i // 4, i % 4]\n","    # Create confusion matrix\n","    cm = confusion_matrix(true_labels_df[cat].values, predicted_labels_df[cat].values, labels=class_labels_data[cat])\n","    # Confusion Matrix\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels_data[cat], yticklabels=class_labels_data[cat], ax=ax)\n","    ax.set_xlabel(\"Predicted\")\n","    ax.set_ylabel(\"True\")\n","    ax.set_title(f\"{cat}, acc {np.round(accuracy_data[cat],3)}\")\n","    \n","fig.delaxes(axs[1, 3])\n","plt.suptitle(f\"Confusion matrices per class on test dataset\")\n","plt.tight_layout()\n","plt.show()\n","\n","fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharex = True, sharey = True) \n","\n","for i, cat in enumerate(reflective_categories):\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Confidence Scores Histogram\n","    #ax.hist(pred_confidence_df[cat], bins=50)\n","    correct_confidence = [pred_confidence_df[cat][i] for i in range(len(predicted_labels_df[cat])) if predicted_labels_df[cat][i] == true_labels_df[cat][i]]\n","    incorrect_confidence = [pred_confidence_df[cat][i] for i in range(len(predicted_labels_df[cat])) if predicted_labels_df[cat][i] != true_labels_df[cat][i]]\n","    ax.hist(correct_confidence, bins=50, color='green', alpha=0.7, label='Correct Predictions')\n","    ax.hist(incorrect_confidence, bins=50, color='red', alpha=0.7, label='Incorrect Predictions')\n","    ax.set_xlabel('Confidence score')\n","    ax.set_ylabel('Number of predictions')\n","    ax.set_title(f\"{cat}, acc {np.round(accuracy_data[cat],3)}\")\n","    ax.legend()\n","\n","fig.delaxes(axs[1, 3])\n","plt.suptitle(f\"Confidence scores per class on test dataset\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Further evaluation : weighted accuracy, F1, AUC"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n","\n","# Initialize variables to store sum of metrics and count of classes\n","sum_accuracy = 0.0\n","sum_weighted_accuracy = 0.0\n","sum_f1 = 0.0\n","sum_auc = 0.0\n","count_classes = 0\n","\n","# Iterate over each 'cat'\n","for cat in reflective_categories:\n","    predicted_labels = predicted_labels_df[cat].values\n","    true_labels = true_labels_df[cat].values\n","    \n","    # Encode labels\n","    label_encoder = LabelEncoder()\n","    true_labels_encoded = label_encoder.fit_transform(true_labels)\n","    predicted_labels_encoded = label_encoder.transform(predicted_labels)\n","    \n","    # Calculate metrics\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    balanced_accuracy = balanced_accuracy_score(true_labels, predicted_labels)\n","    #f1 = f1_score(true_labels, predicted_labels, labels = [cat, 'Other'], pos_label = cat)\n","    f1_scores = f1_score(true_labels_encoded, predicted_labels_encoded, pos_label=label_encoder.transform([cat])[0])\n","    #auc = roc_auc_score(true_labels, predicted_labels) if len(set(true_labels)) > 1 else None  # AUC requires both classes\n","    auc = roc_auc_score(true_labels_encoded, predicted_labels_encoded) if len(set(true_labels_encoded)) > 1 else None\n","    \n","     # Sum metrics\n","    sum_accuracy += accuracy\n","    sum_weighted_accuracy += balanced_accuracy\n","    sum_f1 += f1_scores\n","    if auc is not None:\n","        sum_auc += auc\n","        \n","    # Increment count of classes\n","    count_classes += 1\n","    \n","    # Print metrics for the current class\n","    print(f\"Overall accuracy for class '{cat}' = {accuracy:.4f}\")\n","    print(f\"Balanced accuracy for class '{cat}' = {balanced_accuracy:.4f}\")\n","    print(f\"F1 score for class '{cat}' = {f1_scores:.4f}\")\n","    if auc is not None:\n","        print(f\"AUC for class '{cat}' = {auc:.4f}\")\n","    else:\n","        print(f\"AUC for class '{cat}' cannot be computed due to insufficient data\")\n","    print(\"--------------------------------------\")\n","\n","# Calculate averages\n","avg_accuracy = sum_accuracy / count_classes if count_classes > 0 else 0.0\n","avg_weighted_accuracy = sum_weighted_accuracy / count_classes if count_classes > 0 else 0.0\n","avg_f1 = sum_f1 / count_classes if count_classes > 0 else 0.0\n","avg_auc = sum_auc / count_classes if count_classes > 0 else None\n","\n","# Print average metrics\n","print(\"#########################################\")\n","print(\"############## AVERAGE ##################\")\n","print(\"#########################################\")\n","print(f\"Average accuracy across classes = {avg_accuracy:.4f}\")\n","print(f\"Average weighted accuracy across classes = {avg_weighted_accuracy:.4f}\")\n","print(f\"Average F1 score across classes = {avg_f1:.4f}\")\n","if avg_auc is not None:\n","    print(f\"Average AUC across classes = {avg_auc:.4f}\")\n","else:\n","    print(\"Average AUC across classes cannot be computed due to insufficient data\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3) Learning curves for each class\n","\n","Functions:\n","- preprocess_data_for_LearningCurves_bin\n","- prepare_model_for_LearningCurves\n","- cv_for_LearningCurves_bin"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:13:15.115156Z","iopub.status.busy":"2023-12-21T22:13:15.114787Z","iopub.status.idle":"2023-12-21T22:13:15.137912Z","shell.execute_reply":"2023-12-21T22:13:15.137074Z","shell.execute_reply.started":"2023-12-21T22:13:15.115124Z"},"trusted":true},"outputs":[],"source":["def preprocess_data_for_LC(df_sentences_train, df_sentences_test):\n","    \n","    df_train = pd.DataFrame()\n","    df_test = pd.DataFrame()\n","    \n","    # Preprocess data and labels\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","\n","    max_length_train = max(df_sentences_train['sentence'].apply(lambda sentence: len(sentence.split())))\n","    max_length_test = max(df_sentences_test['sentence'].apply(lambda sentence: len(sentence.split())))\n","\n","    df_train['text'] = df_sentences_train['sentence'].apply(\n","        lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_train))\n","    df_test['text'] = df_sentences_test['sentence'].apply(\n","        lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_test))\n","    \n","    label_encoder_train = LabelEncoder()\n","    label_encoder_test = LabelEncoder()\n","    df_train['label'] = label_encoder_train.fit_transform(df_sentences_train['y']) \n","    df_test['label'] = label_encoder_test.fit_transform(df_sentences_test['y']) # in output for evaluation\n","    \n","    \n","    # Create a custom dataset\n","    class CustomDataset(Dataset):\n","        def __init__(self, text, label):\n","            self.text = text\n","            self.label = label\n","        def __len__(self):\n","            return len(self.text)\n","        def __getitem__(self, idx):\n","            return {\n","                'text': torch.tensor(self.text[idx], dtype=torch.long),\n","                'label': torch.tensor(self.label[idx], dtype=torch.long)\n","                }\n","    train_dataset = CustomDataset(df_train['text'].values, df_train['label'].values)\n","    test_dataset = CustomDataset(df_test['text'].values, df_test['label'].values)\n","\n","    return train_dataset, test_dataset, label_encoder_test\n","\n","def prepare_model_for_LC(model, train_dataset, test_dataset, freeze_weights, batch_size, epochs, learning_rate):\n","\n","    if freeze_weights:\n","        # Freeze all layers except the last two\n","        for param in model.parameters():\n","            param.requires_grad = False\n","        for param in model.classifier.parameters():\n","            param.requires_grad = True\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","    # Set up optimizer and scheduler\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)\n","\n","    return train_loader, test_loader, optimizer, scheduler \n","\n","def cv_for_LearningCurves_bin(df_sentences, freeze_weights, batch_size, epochs, learning_rate, predictions_list, true_labels_list, train_loss_list, train_acc_list, train_balanced_acc_list, val_loss_list, val_acc_list, val_balanced_acc_list, training_examples, N_shuffle, reflective_category):\n","    print(f\"\\n\\nReflective category : {reflective_category}\")\n","    for seed in range(N_shuffle):\n","        print(f\"Shuffle {seed}\")\n","        # shuffle with a different seed each time\n","        df_shuffled = df_sentences.sample(frac = 1, random_state = seed)\n","        for _, nb_train_ex in enumerate(training_examples):\n","            print(f\"Train with {nb_train_ex } examples:\")\n","            train_dataset, label_encoder, val_dataset = preprocess_data_for_LearningCurves_bin(df_shuffled, nb_train_ex, reflective_category)\n","\n","            model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","            train_loader, optimizer, scheduler, val_loader = prepare_model_for_LearningCurves(model, train_dataset, val_dataset, freeze_weights, batch_size, epochs, learning_rate)\n","            #train_loss_loop, train_acc_loop = train(model, train_loader, epochs, optimizer, scheduler, device, plot_visualization = False)\n","            train_loss_loop, val_loss_loop, train_acc_loop, val_acc_loop,  _, _ = train_test(model, train_loader, val_loader, epochs, optimizer, scheduler, device)\n","            print(train_loss_loop)\n","            train_loss_list.append(train_loss_loop[-1]) # take only value of the loss from the last epoch\n","            val_loss_list.append(val_loss_loop[-1])\n","            train_acc_list.extend(train_acc_loop)\n","            val_acc_list.append(val_acc_loop[-1])\n","    \n","    return train_loss_list, train_acc_list, val_loss_list, val_acc_list\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:13:18.147942Z","iopub.status.busy":"2023-12-21T22:13:18.147582Z","iopub.status.idle":"2023-12-21T22:13:18.172500Z","shell.execute_reply":"2023-12-21T22:13:18.171579Z","shell.execute_reply.started":"2023-12-21T22:13:18.147915Z"},"trusted":true},"outputs":[],"source":["def prepare_dataset_for_binclf(df_sentences, batch_size):\n","\n","    df = pd.DataFrame()\n","    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","    max_length_test = max(df_sentences['sentence'].apply(lambda sentence: len(sentence.split())))\n","    df['text'] = df_sentences['sentence'].apply(\n","            lambda x: tokenizer.encode(x, add_special_tokens=True, padding='max_length', truncation = True, max_length=max_length_test))\n","\n","    label_encoder = LabelEncoder()\n","    df['label'] = label_encoder.fit_transform(df_sentences['y'])\n","\n","    # Create a custom dataset\n","    class CustomDataset(Dataset):\n","        def __init__(self, text, label):\n","            self.text = text\n","            self.label = label\n","        def __len__(self):\n","            return len(self.text)\n","        def __getitem__(self, idx):\n","            return {\n","                'text': torch.tensor(self.text[idx], dtype=torch.long),\n","                'label': torch.tensor(self.label[idx], dtype=torch.long)\n","            }\n","\n","    dataset = CustomDataset(df['text'].values, df['label'].values)\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle = True)\n","\n","    return dataloader, label_encoder\n","\n","def train_test_for_LC(model, train_loader, val_loader, epochs, optimizer, scheduler, device):\n","    \n","    #subset_data = list(islice(train_loader, 300))  # Convert islice to a list\n","    # Create a new DataLoader from the subset data\n","    #subset_train_loader = DataLoader(subset_data, batch_size=train_loader.batch_size)\n","    \n","    accuracy_metric = load_metric(\"accuracy\")\n","    train_losses = []\n","    val_losses = []\n","    avg_train_acc_per_epoch = []\n","    avg_val_acc_per_epoch = []\n","    train_confidence_scores = []  # Store confidence scores for train set\n","    val_confidence_scores = []    # Store confidence scores for validation set\n","\n","    #for epoch in range(epochs):\n","    for epoch in range(epochs):\n","        #print(f\"epoch {epoch} running...\")\n","        model.train()\n","        train_loss = []\n","        all_preds_train = []\n","        all_labels_train = []\n","        train_confidence = []\n","\n","        #for batch in train_loader:\n","        for batch in tqdm(subset_train_loader, position = 0, desc= f\"epoch {epoch} running...\"):\n","            optimizer.zero_grad()\n","            inputs = batch['text'].to(device)\n","            labels = batch['label'].to(device)\n","            outputs = model(inputs, labels=labels)\n","            loss = outputs.loss\n","            train_loss.append(loss.item())\n","            predictions_train = torch.argmax(outputs.logits, axis=1)\n","            all_preds_train.extend(predictions_train.cpu().numpy().tolist())\n","            all_labels_train.extend(labels.tolist())\n","            ### compute confidence score\n","            probabilities = torch.softmax(outputs.logits, dim=1)\n","            train_confidence.extend(probabilities.max(dim=1).values.cpu().detach().numpy())  # Confidence scores\n","            ###\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","        avg_epoch_loss_train = sum(train_loss) / len(train_loss)\n","        train_losses.append(avg_epoch_loss_train)\n","        avg_train_acc_per_epoch.append(accuracy_metric.compute(predictions=all_preds_train, references=all_labels_train)[\"accuracy\"])\n","        train_confidence_scores.append(np.mean(train_confidence))  # Store confidence scores\n","        \n","        # Validation loop\n","        model.eval()\n","        val_loss = []\n","        all_preds_val = []\n","        all_labels_val = []\n","        val_confidence = []\n","\n","        with torch.no_grad():\n","            #for batch in tqdm(val_loader, desc=\"Validation\"): \n","            for batch in val_loader:\n","                inputs = batch['text'].to(device)\n","                labels = batch['label'].to(device)\n","                outputs = model(inputs, labels=labels)\n","                loss_val = outputs.loss\n","                val_loss.append(loss_val.item())\n","                predictions_val = torch.argmax(outputs.logits, axis=1)\n","                all_preds_val.extend(predictions_val.cpu().numpy().tolist())\n","                all_labels_val.extend(labels.tolist())\n","                probabilities = torch.softmax(outputs.logits, dim=1)\n","                val_confidence.extend(probabilities.max(dim=1).values.cpu().detach().numpy())  # Confidence scores\n","\n","        avg_epoch_loss_val = sum(val_loss) / len(val_loss)\n","        val_losses.append(avg_epoch_loss_val)\n","        avg_val_acc_per_epoch.append(accuracy_metric.compute(predictions=all_preds_val, references=all_labels_val)[\"accuracy\"])\n","        val_confidence_scores.append(np.mean(val_confidence))  # Store confidence scores\n","\n","    return train_losses, val_losses, avg_train_acc_per_epoch, avg_val_acc_per_epoch, train_confidence_scores, val_confidence_scores\n","\n","def downsample_dataset(df, max_values):\n","    label_counts = dict(df[\"y\"].value_counts().sort_values(ascending=False))\n","\n","    downsampled_label_counts = label_counts\n","    for key, value in label_counts.items():\n","        downsampled_label_counts[key] = value if value < max_values else max_values\n","\n","    # Downsample to the maximum desired labels per class\n","    under_sampler = RandomUnderSampler(sampling_strategy= downsampled_label_counts)\n","    df_downsampled, _ = under_sampler.fit_resample(df, df['y'])\n","\n","    # sample the dataset randomly\n","    df_downsampled = df_downsampled.sample(frac = 1)\n","    print(f\"Length of the downsampled dataframe: {len(df_downsampled)}\")\n","    \n","    sns.histplot(df_downsampled['y'])\n","    plt.xticks(rotation = 45)\n","    plt.title(\"Dataset downsampled\")\n","    plt.show()\n","\n","    return df_downsampled\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:13:26.708559Z","iopub.status.busy":"2023-12-21T22:13:26.708175Z","iopub.status.idle":"2023-12-21T22:13:27.041359Z","shell.execute_reply":"2023-12-21T22:13:27.040364Z","shell.execute_reply.started":"2023-12-21T22:13:26.708528Z"},"trusted":true},"outputs":[],"source":["print(f\"Length train dataset: {len(train_dataset)}\")\n","train_dataset_downsampled = downsample_dataset(train_dataset, 400)\n","#print(f\"Length train dataset: {len(train_dataset)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:15:41.044921Z","iopub.status.busy":"2023-12-21T22:15:41.044129Z","iopub.status.idle":"2023-12-21T22:15:41.400399Z","shell.execute_reply":"2023-12-21T22:15:41.399610Z","shell.execute_reply.started":"2023-12-21T22:15:41.044887Z"},"trusted":true},"outputs":[],"source":["dataset_downsampled = downsample_dataset(merged_df, 400)"]},{"cell_type":"markdown","metadata":{},"source":["### By splitting the dataframe and re process sentences each time"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:49:54.427123Z","iopub.status.busy":"2023-12-21T22:49:54.426437Z","iopub.status.idle":"2023-12-21T22:55:22.012546Z","shell.execute_reply":"2023-12-21T22:55:22.011502Z","shell.execute_reply.started":"2023-12-21T22:49:54.427089Z"},"trusted":true},"outputs":[],"source":["%%time\n","\n","# Set hyperparameters\n","batch_size = 8\n","epochs = 2\n","learning_rate = 2e-5\n","freeze_weights = False\n","\n","# Create a dictionary to store DataFrames\n","dfs_train = {}\n","dfs_val = {}\n","dfs_train_acc = {}\n","dfs_train_balanced_acc = {}\n","dfs_val_acc = {}\n","dfs_val_balanced_acc = {}\n","dfs_test_confidence = {}\n","\n","#training_examples = [50, 100, 150, 200, 250, 300]\n","training_examples = [200, 400, 600, 800]#, 1000]\n","#training_examples = [500, 1000] #, 1500, 2000]\n","N_shuffle_total = 2\n","reflective_categories = ['Intention', 'Perspective'] \n","# reflective_categories = ['Experience']#, 'Feeling', 'Difficulty', 'Belief'] \n","print(reflective_categories)\n","print(f\"Number of sentences in balanced dataset: {len(dataset_downsampled)}\")\n","print(f\"Length of train set: {int(len(dataset_downsampled) * 0.8)}\")\n","print(f\"Length of test set: {int(len(dataset_downsampled) * 0.2)}\")\n","\n","for cat in reflective_categories:\n","    print(f\"\\n\\nStarting Learning curves for category : {cat}\")\n","    train_loss_list = []\n","    train_acc_list = []\n","    train_balanced_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","    val_balanced_acc_list = []\n","    test_confidence_score_list = []\n","    \n","    # Prepare dataset for binary classification\n","    df_sentences_bin = dataset_downsampled.copy()\n","    df_sentences_bin['y'] = np.where(df_sentences_bin['y'] == cat, cat, 'Other')\n","    \n","    for i, N_shuffle in enumerate(range(N_shuffle_total)):\n","        print(f\"\\nShuffle {i+1}:\")\n","        # Split between train and test\n","        train_dataset_bin, test_dataset_bin = train_test_split(df_sentences_bin, test_size=0.2, random_state=42)\n","        \n","        # Initialize the pre-trained BERT model for bin clf\n","        model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","        \n","        for nb_train_ex in training_examples:\n","            print(f\"Train with {nb_train_ex} sentences\")\n","            # preprocess sentences \n","            train_dataset_bin_pp, test_dataset_bin_pp, label_encoder_test = preprocess_data_for_LC(train_dataset_bin.head(nb_train_ex), test_dataset_bin)\n","            # prepare model\n","            train_loader, test_loader, optimizer, scheduler = prepare_model_for_LC(model, train_dataset_bin_pp, test_dataset_bin_pp, freeze_weights, batch_size, epochs, learning_rate)\n","\n","            #train_loss_fold, val_loss_fold, train_acc_fold, val_acc_fold, _, test_confidence_scores, _ = train_test(model, train_loader, test_loader, epochs, optimizer, scheduler, device)\n","            train_loss_fold, val_loss_fold, train_acc_fold, val_acc_fold, _, test_confidence_scores, _, train_balanced_acc_fold, val_balanced_acc_fold = train_test(model, train_loader, test_loader, epochs, optimizer, scheduler, device)\n","        \n","            train_loss_list.append(train_loss_fold[-1])\n","            train_acc_list.append(train_acc_fold[-1])\n","            train_balanced_acc_list.append(train_balanced_acc_fold[-1])\n","            val_loss_list.append(val_loss_fold[-1])\n","            val_acc_list.append(val_acc_fold[-1])\n","            val_balanced_acc_list.append(val_balanced_acc_fold[-1])\n","            test_confidence_score_list.append(test_confidence_scores[-1])\n","            \n","    # Train loss\n","    train_loss_array = np.array(train_loss_list).reshape(N_shuffle_total, len(training_examples))\n","    mean_train_loss = np.mean(train_loss_array, axis=0)\n","    ci_train_loss = np.percentile(train_loss_array, [2.5, 97.5], axis=0)\n","    \n","    # Val loss\n","    val_loss_array = np.array(val_loss_list).reshape(N_shuffle_total,len(training_examples))\n","    mean_val_loss = np.mean(val_loss_array, axis=0)\n","    ci_val_loss = np.percentile(val_loss_array, [2.5, 97.5], axis=0)\n","    \n","    # Train acc\n","    train_acc_array = np.array(train_acc_list).reshape(N_shuffle_total,len(training_examples))\n","    mean_train_acc = np.mean(train_acc_array, axis=0)\n","    ci_train_acc = np.percentile(train_acc_array, [2.5, 97.5], axis=0)\n","    \n","    # Val acc\n","    val_acc_array = np.array(val_acc_list).reshape(N_shuffle_total,len(training_examples))\n","    mean_val_acc = np.mean(val_acc_array, axis=0)\n","    ci_val_acc = np.percentile(val_acc_array, [2.5, 97.5], axis=0)\n","    \n","    # Balanced accuracy on train set\n","    train_balanced_acc_array = np.array(train_balanced_acc_list).reshape(N_shuffle_total,len(training_examples))\n","    mean_train_balanced_acc = np.mean(train_balanced_acc_array, axis=0)\n","    ci_train_balanced_acc = np.percentile(train_balanced_acc_array, [2.5, 97.5], axis=0)\n","\n","    # Balanced accuracy on validation set\n","    val_balanced_acc_array = np.array(val_balanced_acc_list).reshape(N_shuffle_total,len(training_examples))\n","    mean_val_balanced_acc = np.mean(val_balanced_acc_array, axis=0)\n","    ci_val_balanced_acc = np.percentile(val_balanced_acc_array, [2.5, 97.5], axis=0)\n","    \n","    # Test Confidence scores\n","    test_conf_array = np.array(test_confidence_score_list).reshape(N_shuffle_total,len(training_examples))\n","    mean_test_conf = np.mean(test_conf_array, axis=0)\n","    ci_test_conf = np.percentile(test_conf_array, [2.5, 97.5], axis=0)\n","\n","    # Create a DataFrame for Seaborn\n","    df_train_loss = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Train_Loss': mean_train_loss,\n","        'Lower_CI': ci_train_loss[0],\n","        'Upper_CI': ci_train_loss[1]})\n","    \n","    df_val_loss = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Val_Loss': mean_val_loss,\n","        'Lower_CI': ci_val_loss[0],\n","        'Upper_CI': ci_val_loss[1]})\n","    \n","    df_train_acc = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Train_Acc': mean_train_acc,\n","        'Lower_CI': ci_train_acc[0],\n","        'Upper_CI': ci_train_acc[1]})\n","    \n","    df_val_acc = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Val_Acc': mean_val_acc,\n","        'Lower_CI': ci_val_acc[0],\n","        'Upper_CI': ci_val_acc[1]})\n","    \n","    df_train_balanced_acc = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Train_Balanced_Acc': mean_train_balanced_acc,\n","        'Lower_CI': ci_train_balanced_acc[0],\n","        'Upper_CI': ci_train_balanced_acc[1]})\n","\n","    df_val_balanced_acc = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Val_Balanced_Acc': mean_val_balanced_acc,\n","        'Lower_CI': ci_val_balanced_acc[0],\n","        'Upper_CI': ci_val_balanced_acc[1]})\n","    \n","    df_test_confidence = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Test_Conf': mean_test_conf,\n","        'Lower_CI': ci_test_conf[0],\n","        'Upper_CI': ci_test_conf[1]})\n","    \n","    dfs_train[f'{cat}'] = df_train_loss\n","    dfs_val[f'{cat}'] = df_val_loss\n","    dfs_train_acc[f'{cat}'] = df_train_acc\n","    dfs_val_acc[f'{cat}'] = df_val_acc\n","    dfs_test_confidence[f'{cat}'] = df_test_confidence\n","    dfs_train_balanced_acc[f'{cat}'] = df_train_balanced_acc \n","    dfs_val_balanced_acc[f'{cat}'] = df_val_balanced_acc  "]},{"cell_type":"markdown","metadata":{},"source":["### Visualize results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-21T22:56:31.057961Z","iopub.status.busy":"2023-12-21T22:56:31.057171Z","iopub.status.idle":"2023-12-21T22:56:33.608165Z","shell.execute_reply":"2023-12-21T22:56:33.607276Z","shell.execute_reply.started":"2023-12-21T22:56:31.057927Z"},"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharey = True)  \n","\n","# Sample iteration over the dictionary to plot subplots\n","for i, cat in enumerate(reflective_categories):\n","    df_train = dfs_train[cat]\n","    df_val = dfs_val[cat]\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Mean lineplot\n","    sns.pointplot(data=df_train, x='N_training_examples', y='Mean_Train_Loss', color='blue', ax = ax)\n","    sns.pointplot(data=df_val, x='N_training_examples', y='Mean_Val_Loss', color='orange', ax = ax) \n","    \n","    # Fill between the confidence interval\n","    ax.fill_between(df_train['N_training_examples'], df_train['Lower_CI'], df_train['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","    ax.fill_between(df_val['N_training_examples'], df_val['Lower_CI'], df_val['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","    \n","    ax.set_xticks(np.arange(len(training_examples)), training_examples)\n","    ax.set_xlabel('Nb Training examples')\n","    ax.set_ylabel(\"Loss\")\n","    ax.set_title(f\"{cat}\") \n","    ax.legend()\n","    \n","fig.delaxes(axs[1, 3])\n","plt.suptitle(f\"Loss with 95% CI per class with bs : {batch_size}, lr : {learning_rate}, {epochs} epochs\")\n","plt.tight_layout()\n","plt.show()\n","\n","fig, axs = plt.subplots(2, 4, figsize=(15, 6), sharey = True)  \n","\n","# Sample iteration over the dictionary to plot subplots\n","for i, cat in enumerate(reflective_categories):\n","    df_train = dfs_train_balanced_acc[cat]\n","    df_acc = dfs_val_balanced_acc[cat]\n","    #df_test_conf = dfs_test_confidence[cat]\n","    ax = axs[i // 4, i % 4]\n","    \n","    # Mean lineplot\n","    sns.pointplot(data=df_train, x='N_training_examples', y='Mean_Train_Balanced_Acc', color='blue', ax = ax)\n","    sns.pointplot(data=df_acc, x='N_training_examples', y='Mean_Val_Balanced_Acc', color='orange', ax = ax) \n","    #sns.pointplot(data=df_test_conf, x='N_training_examples', y='Mean_Test_Conf', color='green', ax = ax) \n","    \n","    # Fill between the confidence interval\n","    ax.fill_between(df_train['N_training_examples'], df_train['Lower_CI'], df_train['Upper_CI'], color='blue', alpha=0.3, label = 'train')\n","    ax.fill_between(df_acc['N_training_examples'], df_acc['Lower_CI'], df_acc['Upper_CI'], color='orange', alpha=0.3, label = 'val')\n","    #ax.fill_between(df_test_conf['N_training_examples'], df_test_conf['Lower_CI'], df_test_conf['Upper_CI'], color='green', alpha=0.3, label = 'test confidence')\n","    \n","    ax.set_xticks(np.arange(len(training_examples)), training_examples)\n","    ax.set_xlabel('Nb Training examples')\n","    ax.set_ylabel(\"Balanced Accuracy\")\n","    ax.set_title(f\"{cat}\") \n","    ax.legend()\n","\n","fig.delaxes(axs[1, 3])\n","plt.suptitle(f\"Balanced Accuracy with 95% CI per class with bs : {batch_size}, lr : {learning_rate}, {epochs} epochs\")\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Experiment 5 : Learning curves with the most confident predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T15:50:26.612679Z","iopub.status.busy":"2023-12-18T15:50:26.611739Z","iopub.status.idle":"2023-12-18T15:50:26.895603Z","shell.execute_reply":"2023-12-18T15:50:26.894683Z","shell.execute_reply.started":"2023-12-18T15:50:26.612640Z"},"trusted":true},"outputs":[],"source":["print(f\"Length dataset: {len(merged_df)}\")\n","dataset_downsampled = downsample_dataset(merged_df, 600)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-18T15:51:42.446067Z","iopub.status.busy":"2023-12-18T15:51:42.445634Z","iopub.status.idle":"2023-12-18T15:51:55.750908Z","shell.execute_reply":"2023-12-18T15:51:55.750007Z","shell.execute_reply.started":"2023-12-18T15:51:42.446028Z"},"trusted":true},"outputs":[],"source":["%%time\n","\n","# Set hyperparameters\n","batch_size = 8\n","epochs = 2  ## One epoch = self-learning \n","learning_rate = 2e-5\n","freeze_weights = False\n","\n","# Create a dictionary to store DataFrames\n","dfs_train = {}\n","dfs_val = {}\n","dfs_train_acc = {}\n","dfs_val_acc = {}\n","dfs_test_confidence = {}\n","\n","#training_examples = [50, 100, 150, 200, 250, 300]\n","training_examples = [200, 400] # 600, 800]#, 1000]\n","#training_examples = [500, 1000] #, 1500, 2000]\n","N_shuffle_total = 3\n","reflective_categories = ['Experience']#, 'Feeling', 'Difficulty', 'Belief'] \n","print(reflective_categories)\n","print(f\"Number of sentences in balanced dataset: {len(dataset_downsampled)}\")\n","print(f\"Length of train set: {int(len(dataset_downsampled) * 0.8)}\")\n","print(f\"Length of test set: {int(len(dataset_downsampled) * 0.2)}\")\n","\n","for cat in reflective_categories:\n","    print(f\"\\n\\nStarting Learning curves for category : {cat}\")\n","    train_loss_list = []\n","    train_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","    all_train_confidence_score_list = []\n","    avg_test_confidence_score_per_epoch_list = []\n","    \n","    # Prepare dataset for binary classification\n","    df_sentences_bin = dataset_downsampled.copy()\n","    df_sentences_bin['y'] = np.where(df_sentences_bin['y'] == cat, cat, 'Other')\n","    \n","    for i, N_shuffle in enumerate(range(N_shuffle_total)):\n","        print(f\"\\nShuffle {i+1}:\")\n","        # Split between train and test\n","        train_dataset_bin, test_dataset_bin = train_test_split(df_sentences_bin, test_size=0.2, random_state=42)\n","        \n","        # Initialize the pre-trained BERT model for bin clf\n","        model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","        \n","        combined_data = train_dataset_bin.head(training_examples[0])\n","        \n","        for N , nb_train_ex in enumerate(training_examples):\n","            # add the most confident predictions to the training set\n","            print(f\"Train with {len(combined_data)} sentences\")\n","            # preprocess sentences \n","            train_dataset_bin_pp, test_dataset_bin_pp, label_encoder_test = preprocess_data_for_LC(combined_data, test_dataset_bin)\n","            # prepare model\n","            train_loader, test_loader, optimizer, scheduler = prepare_model_for_LC(model, train_dataset_bin_pp, test_dataset_bin_pp, freeze_weights, batch_size, epochs, learning_rate)\n","\n","            train_loss_fold, val_loss_fold, train_acc_fold, val_acc_fold, train_confidence_scores_avg_per_epoch, test_confidence_scores_avg_per_epoch, all_train_confidence = train_test(model, train_loader, test_loader, epochs, optimizer, scheduler, device)\n","                                                                                                                         \n","            train_loss_list.append(train_loss_fold[-1])\n","            train_acc_list.append(train_acc_fold[-1])\n","            val_loss_list.append(val_loss_fold[-1])\n","            val_acc_list.append(val_acc_fold[-1])\n","            #all_train_confidence_score_list.extend(all_train_confidence)\n","            avg_test_confidence_score_per_epoch_list.append(test_confidence_scores_avg_per_epoch[-1])\n","            \n","            num_values = len(all_train_confidence)\n","            num_top_20_percent = int(num_values * 0.2)  # Calculate the number of values in the top 20%\n","            indices_top_20_percent = sorted(range(num_values), key=lambda i: all_train_confidence[i], reverse=True)[:num_top_20_percent]\n","\n","            df_most_confident = dataset_downsampled.iloc[indices_top_20_percent]\n","            \n","            new_data = train_dataset_bin.iloc[N*training_examples[0]: (N+1)*training_examples[0]]\n","            combined_data = pd.concat([df_most_confident, new_data])\n","            print(f\"Length of combined dataset: {len(combined_data)}\")\n","        \n","    # Train loss\n","    train_loss_array = np.array(train_loss_list).reshape(N_shuffle_total, len(training_examples))\n","    mean_train_loss = np.mean(train_loss_array, axis=0)\n","    ci_train_loss = np.percentile(train_loss_array, [2.5, 97.5], axis=0)\n","    \n","    # Val loss\n","    val_loss_array = np.array(val_loss_list).reshape(N_shuffle_total,len(training_examples))\n","    mean_val_loss = np.mean(val_loss_array, axis=0)\n","    ci_val_loss = np.percentile(val_loss_array, [2.5, 97.5], axis=0)\n","    \n","    # Train acc\n","    train_acc_array = np.array(train_acc_list).reshape(N_shuffle_total,len(training_examples))\n","    mean_train_acc = np.mean(train_acc_array, axis=0)\n","    ci_train_acc = np.percentile(train_acc_array, [2.5, 97.5], axis=0)\n","    \n","    # Val acc\n","    val_acc_array = np.array(val_acc_list).reshape(N_shuffle_total,len(training_examples))\n","    mean_val_acc = np.mean(val_acc_array, axis=0)\n","    ci_val_acc = np.percentile(val_acc_array, [2.5, 97.5], axis=0)\n","    \n","    # Test Confidence scores\n","    test_conf_array = np.array(avg_test_confidence_score_per_epoch_list).reshape(N_shuffle_total,len(training_examples))\n","    mean_test_conf = np.mean(test_conf_array, axis=0)\n","    ci_test_conf = np.percentile(test_conf_array, [2.5, 97.5], axis=0)\n","\n","    # Create a DataFrame for Seaborn\n","    df_train_loss = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Train_Loss': mean_train_loss,\n","        'Lower_CI': ci_train_loss[0],\n","        'Upper_CI': ci_train_loss[1]})\n","    \n","    df_val_loss = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Val_Loss': mean_val_loss,\n","        'Lower_CI': ci_val_loss[0],\n","        'Upper_CI': ci_val_loss[1]})\n","    \n","    df_train_acc = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Train_Acc': mean_train_acc,\n","        'Lower_CI': ci_train_acc[0],\n","        'Upper_CI': ci_train_acc[1]})\n","    \n","    df_val_acc = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Val_Acc': mean_val_acc,\n","        'Lower_CI': ci_val_acc[0],\n","        'Upper_CI': ci_val_acc[1]})\n","    \n","    df_test_confidence = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Test_Conf': mean_test_conf,\n","        'Lower_CI': ci_test_conf[0],\n","        'Upper_CI': ci_test_conf[1]})\n","    \n","    dfs_train[f'{cat}'] = df_train_loss\n","    dfs_val[f'{cat}'] = df_val_loss\n","    dfs_train_acc[f'{cat}'] = df_train_acc\n","    dfs_val_acc[f'{cat}'] = df_val_acc\n","    dfs_test_confidence[f'{cat}'] = df_test_confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["values = [0.89725614, 0.8265314, 0.8608944, 0.89096713, 0.90152985, 0.8810586, 0.8641204, 0.779013, 0.9036705, 0.8782628, 0.8470351, 0.862957, 0.87726593, 0.85752606, 0.8642521, 0.89463615, 0.89705205, 0.88434637, 0.8844721, 0.8724542, 0.8710404, 0.86373454, 0.87535864, 0.8877713, 0.8403641, 0.8795528, 0.8588633, 0.8833332, 0.85883814, 0.7513898, 0.87752813, 0.89346623, 0.86391985, 0.8336804, 0.83276635, 0.8329713, 0.8751115, 0.90970105, 0.8292461, 0.86291826, 0.8639757, 0.873903, 0.87614065, 0.8809002, 0.83957916, 0.8515999, 0.86006474, 0.83797777, 0.85472125, 0.85212344, 0.8218158, 0.80510116, 0.7178283, 0.87010324, 0.836947, 0.83996314, 0.8139497, 0.81396234, 0.849028, 0.8285842, 0.80438775, 0.8583806, 0.8627805, 0.81667066, 0.8049326, 0.84818, 0.82001126, 0.81965625, 0.87334657, 0.8313316, 0.7719984, 0.8333738, 0.7940738, 0.83995056, 0.8343295, 0.7970121, 0.7900876, 0.83439934, 0.8432067, 0.82171685, 0.8278204, 0.8148168, 0.8216123, 0.84128857, 0.74447674, 0.84744465, 0.84314924, 0.83186847, 0.70089346, 0.8448653, 0.8065221, 0.8073163, 0.69540477, 0.8533329, 0.8652067, 0.85866153, 0.8319706, 0.8198268, 0.82017654, 0.8545485, 0.8350983, 0.8119053, 0.80813396, 0.82151556, 0.80893975, 0.8763131, 0.83548516, 0.85596704, 0.8543422, 0.80797094, 0.8430984, 0.8113218, 0.84107375, 0.80528545, 0.8430511, 0.8267623, 0.83612174, 0.8538626, 0.84286916, 0.772975, 0.8017599, 0.8248337, 0.8434411, 0.8088821, 0.80819887, 0.8080551, 0.83073604, 0.8302567, 0.7885074, 0.8553188, 0.8393506, 0.8509006, 0.8480079, 0.7951159, 0.8022355, 0.82036436, 0.8583823, 0.8570997, 0.81445855, 0.8481593, 0.8223166, 0.84600216, 0.83105963, 0.8030795, 0.83624935, 0.78268456, 0.83683234, 0.8238378, 0.82838446, 0.84227175, 0.8452065, 0.80628335, 0.8684133, 0.80064934, 0.80887806, 0.81648415, 0.8277713, 0.80383104, 0.8106005, 0.8258066, 0.85887057, 0.8450083, 0.8295496, 0.81164175, 0.8439562, 0.77985466, 0.8150946, 0.82951474, 0.82633066, 0.85161924, 0.86996955, 0.8402585, 0.8397682, 0.8583724, 0.8118849, 0.8363616, 0.8685401, 0.81430596, 0.86222714, 0.84854424, 0.8601118, 0.81300575, 0.8078579, 0.8178351, 0.8080628, 0.86383814, 0.85081226, 0.86024946, 0.8267963, 0.86264116, 0.84713376, 0.8009532, 0.83537334, 0.77203023, 0.8106392, 0.80602807, 0.8346353, 0.8292258, 0.7603937, 0.82759184]\n","[0.738134, 0.8352792]\n","print(len(values))\n","\n","# Find the indices of the top 20% values\n","num_values = len(values)\n","num_top_20_percent = int(num_values * 0.2)  # Calculate the number of values in the top 20%\n","indices_top_20_percent = sorted(range(num_values), key=lambda i: values[i], reverse=True)[:num_top_20_percent]\n","\n","print(indices_top_20_percent)\n","\n","df_most_confident = dataset_downsampled.iloc[indices_top_20_percent]\n","sns.histplot(df_most_confident['y'])\n","print(len(df_most_confident))\n","df_most_confident.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["other_data = dataset_downsampled.iloc[500:1000]\n","print(len(other_data))\n","sns.histplot(other_data['y'])\n","other_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["combined_data = pd.concat([df_most_confident, other_data])\n","print(len(combined_data))\n","sns.histplot(combined_data['y'])\n","combined_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["### By splitting the train_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","\n","# Set hyperparameters\n","batch_size = 8\n","epochs = 2\n","learning_rate = 2e-5\n","freeze_weights = False\n","\n","# Create a dictionary to store DataFrames\n","dfs_train = {}\n","dfs_val = {}\n","dfs_train_acc = {}\n","dfs_val_acc = {}\n","\n","#training_examples = [50, 100, 150, 200, 250, 300]\n","training_examples = [100, 300, 500]\n","N_shuffle_total = 2\n","reflective_categories = ['Experience', 'Feeling'] #top3_classes #['Experience', 'Feeling']\n","print(reflective_categories)\n","print(f\"Number of sentences in balanced dataset: {len(train_dataset_downsampled)}\")\n","\n","for cat in reflective_categories:\n","    print(f\"\\nStarting Learning curves for category : {cat}\")\n","    train_loss_list = []\n","    train_acc_list = []\n","    val_loss_list = []\n","    val_acc_list = []\n","    \n","    # Prepare dataset for binary classification\n","    df_sentences_bin = train_dataset_downsampled.iloc[:600].copy()\n","    df_sentences_bin['y'] = np.where(df_sentences_bin['y'] == cat, cat, 'Other')\n","    \n","    for N_shuffle in range(N_shuffle_total):\n","        # Split between train and test\n","        train_dataset_bin, test_dataset_bin = train_test_split(df_sentences_bin, test_size=0.2, random_state=42)\n","        # preprocess sentences for different\n","        train_dataset_bin_pp, test_dataset_bin_pp, label_encoder_test = preprocess_data_for_LC(train_dataset_bin, test_dataset_bin)\n","        # Initialize the pre-trained BERT model for bin clf\n","        model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","        # prepare model\n","        train_loader, test_loader, optimizer, scheduler = prepare_model_for_LC(model, train_dataset_bin_pp, test_dataset_bin_pp, freeze_weights, batch_size, epochs, learning_rate)\n","        \n","        for nb_train_ex in training_examples:\n","            subset_data = list(islice(train_loader, size))  # Convert islice to a list\n","            # Create a new DataLoader from the subset data\n","            subset_train_loader = DataLoader(subset_data, batch_size=train_loader.batch_size)\n","            print(f\"Number of samples in training: {len(subset_train_loader) * subset_train_loader.batch_size}\")\n","            train_loss_fold, val_loss_fold, train_acc_fold, val_acc_fold, _, _ = train_test(model, subset_train_loader, test_loader, epochs, optimizer, scheduler, device)\n","        \n","            train_loss_list.extend(train_loss_fold[-1])\n","            train_acc_list.extend(train_acc_fold[-1])\n","            val_loss_list.extend(val_loss_fold[-1])\n","            val_acc_list.extend(val_acc_fold[-1]) \n","            \n","    # Train loss\n","    train_loss_array = np.array(train_loss_list).reshape(N_shuffle_total, len(training_examples))\n","    mean_train_loss = np.mean(train_loss_array, axis=0)\n","    ci_train_loss = np.percentile(train_loss_array, [2.5, 97.5], axis=0)\n","    \n","    # Val loss\n","    val_loss_array = np.array(val_loss_list).reshape(N_shuffle,len(training_examples))\n","    mean_val_loss = np.mean(val_loss_array, axis=0)\n","    ci_val_loss = np.percentile(val_loss_array, [2.5, 97.5], axis=0)\n","    \n","    # Train acc\n","    train_acc_array = np.array(train_acc_list).reshape(N_shuffle,len(training_examples))\n","    mean_train_acc = np.mean(train_acc_array, axis=0)\n","    ci_train_acc = np.percentile(train_acc_array, [2.5, 97.5], axis=0)\n","    \n","    # Val acc\n","    val_acc_array = np.array(val_acc_list).reshape(N_shuffle,len(training_examples))\n","    mean_val_acc = np.mean(val_acc_array, axis=0)\n","    ci_val_acc = np.percentile(val_acc_array, [2.5, 97.5], axis=0)\n","\n","    # Create a DataFrame for Seaborn\n","    df_train_loss = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Train_Loss': mean_train_loss,\n","        'Lower_CI': ci_train_loss[0],\n","        'Upper_CI': ci_train_loss[1]})\n","    \n","    df_val_loss = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Val_Loss': mean_val_loss,\n","        'Lower_CI': ci_val_loss[0],\n","        'Upper_CI': ci_val_loss[1]})\n","    \n","    df_train_acc = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Train_Acc': mean_train_acc,\n","        'Lower_CI': ci_train_acc[0],\n","        'Upper_CI': ci_train_acc[1]})\n","    \n","    df_val_acc = pd.DataFrame({\n","        'N_training_examples': np.arange(len(training_examples)),\n","        'Mean_Val_Acc': mean_val_acc,\n","        'Lower_CI': ci_val_acc[0],\n","        'Upper_CI': ci_val_acc[1]})\n","    \n","    dfs_train[f'{cat}'] = df_train_loss\n","    dfs_val[f'{cat}'] = df_val_loss\n","    dfs_train_acc[f'{cat}'] = df_train_acc\n","    dfs_val_acc[f'{cat}'] = df_val_acc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3964652,"sourceId":6902157,"sourceType":"datasetVersion"}],"dockerImageVersionId":30616,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
